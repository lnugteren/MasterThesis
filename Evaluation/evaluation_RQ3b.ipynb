{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rbo\n",
    "\n",
    "\n",
    "colors = {1 : '#8f2011', 2: '#2B4C85', 3: '#91CDB7', 4: '#E7D995', 5: '#D68A91', \n",
    "          6: '#E89762', 7: '#50AFC7', 8: '#CDB29E', 9: '#C7CBCC', 10: '#A6C5D6',\n",
    "          11: '#6B7B8E', 12: '#957DAD', 13: '#D5DEC8', 14: '#DDE9ED'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = {\"baseline_Office_Products_clust\": [5.0, 18.611099999999993, 17.380899999999997, 13.815799999999996, 19.25, 18.103499999999997, 18.256299999999996, 17.660300000000007, 13.219700000000003, 23.836699999999993, 28.2744, 18.7641, 22.1755, 21.635599999999997, 24.927899999999994, 19.450199999999995],\n",
    "             \"baseline_Movies_and_TV_clust\": [0.0, 3.333299999999994, 12.261899999999997, 21.447400000000002, 17.833299999999994, 21.5805, 13.256299999999996, 20.977599999999995, 19.684399999999997, 18.030600000000007, 19.309799999999996, 20.233099999999993, 16.670699999999997, 18.7008, 21.2162, 16.285600000000002],\n",
    "             \"baseline_Electronics_clust\": [0.0, 18.888900000000007, 20.357200000000006, 13.3553, 23.041700000000006, 23.965500000000006, 26.407600000000002, 17.323700000000002, 18.787899999999993, 21.551000000000002, 22.382199999999997, 23.382800000000003, 15.210300000000004, 26.262900000000002, 24.5856, 21.095699999999994],\n",
    "             \"baseline_Home_and_Kitchen_clust\": [36.25, 5.0, 25.595200000000006, 14.671099999999996, 26.25, 21.034499999999994, 16.764700000000005, 26.153800000000004, 19.9242, 19.357100000000003, 21.195300000000003, 22.210499999999996, 24.0385, 19.171800000000005, 20.252300000000005, 21.946200000000005],\n",
    "             \"baseline_Sports_and_Outdoors_clust\": [0.0, 23.888900000000007, 2.8571000000000026, 22.171099999999996, 20.458299999999994, 24.827600000000004, 24.495800000000003, 16.746799999999993, 19.6212, 15.959199999999996, 18.308099999999996, 22.203400000000002, 18.912300000000002, 21.521699999999996, 30.6712, 19.379000000000005],\n",
    "             \"baseline_avg_clust\": [8.25, 13.94444, 15.690460000000002, 17.092139999999997, 21.36666, 21.90232, 19.83614, 19.77244, 18.24748, 19.74692, 21.89396, 21.35878, 19.40146, 21.45856, 24.33064, 19.63134],\n",
    "             \"baseline_Office_Products_run\": [0.05448555946350098, 0.31552624702453613, 0.8831596374511719, 3.618621349334717, 6.730201005935669, 7.80850887298584, 27.702049732208252, 27.06011438369751, 78.68177437782288, 45.39916634559631, 147.5757429599762, 442.2324664592743, 159.10864281654358, 90.10949420928955, 256.59652280807495, 340.9599621295929],\n",
    "             \"baseline_Movies_and_TV_run\": [0.04722857475280762, 1.1784977912902832, 0.8528079986572266, 8.51487684249878, 19.5964195728302, 32.786688804626465, 71.72824907302856, 113.7187728881836, 35.13785982131958, 156.2257480621338, 660.7518954277039, 236.54234266281128, 98.22892928123474, 735.6667339801788, 104.07884216308594, 595.1121373176575],\n",
    "             \"baseline_Electronics_run\": [0.053472280502319336, 2.1010425090789795, 2.919151544570923, 3.594113349914551, 30.617064952850342, 104.53532123565674, 73.74175953865051, 344.3559377193451, 273.2131395339966, 338.97044229507446, 218.20475244522095, 2356.2287406921387, 1354.1414065361023, 1517.1713445186615, 175.69297528266907, 1316.416113615036],\n",
    "             \"baseline_Home_and_Kitchen_run\": [4.541350364685059, 2.1068339347839355, 2.669426918029785, 3.1710526943206787, 46.406383752822876, 28.465285778045654, 32.39564108848572, 32.10050964355469, 49.76962971687317, 105.97833323478699, 44.58966565132141, 207.87276482582092, 523.6368310451508, 183.76712703704834, 93.92786931991577, 994.7171490192413],\n",
    "             \"baseline_Sports_and_Outdoors_run\": [0.04317212104797363, 0.3852384090423584, 0.7091190814971924, 36.61021637916565, 27.34624171257019, 27.56926202774048, 114.25029063224792, 17.88065195083618, 38.20409059524536, 271.567095041275, 85.09123516082764, 145.26176857948303, 86.3480076789856, 317.13807702064514, 109.12904930114746, 690.0298011302948],\n",
    "             \"baseline_avg_run\": [0.947941780090332, 1.2174277782440186, 1.6067330360412597, 11.101776123046875, 26.139262199401855, 40.23301334381104, 63.963598012924194, 107.02319731712342, 95.00129880905152, 183.6281569957733, 231.24265832901, 677.6276166439056, 444.2927634716034, 568.7705553531647, 147.88505177497865, 787.4470326423645],\n",
    "             \"baseline_Office_Products_ranksize\": [1, 1, 3, 4, 4, 10, 10, 10, 12, 15, 16, 13, 13, 13, 12, 18],\n",
    "             \"baseline_Movies_and_TV_ranksize\": [0, 1, 3, 8, 7, 12, 10, 11, 14, 13, 19, 13, 13, 8, 16, 20],\n",
    "             \"baseline_Electronics_ranksize\": [0, 4, 5, 6, 5, 15, 10, 11, 9, 18, 13, 19, 16, 22, 16, 15],\n",
    "             \"baseline_Home_and_Kitchen_ranksize\": [3, 2, 5, 9, 10, 6, 9, 16, 13, 16, 9, 15, 18, 11, 15, 15],\n",
    "             \"baseline_Sports_and_Outdoors_ranksize\": [0, 5, 2, 8, 13, 13, 14, 7, 16, 15, 13, 12, 13, 11, 8, 14],\n",
    "             \"baseline_avg_ranksize\": [0.8, 2.6, 3.6, 7.0, 7.8, 11.2, 10.6, 11.0, 12.8, 15.4, 14.0, 14.4, 14.6, 13.0, 13.4, 16.4],\n",
    "             \"baseline_Office_Products_perc\": [10.0, 5.0, 10.0, 10.0, 8.0, 16.666666666666668, 14.285714285714286, 12.5, 13.333333333333334, 15.0, 14.545454545454545, 10.833333333333334, 10.0, 9.285714285714286, 8.0, 11.25],\n",
    "             \"baseline_Movies_and_TV_perc\": [0.0, 5.0, 10.0, 20.0, 14.0, 20.0, 14.285714285714286, 13.75, 15.555555555555555, 13.0, 17.272727272727273, 10.833333333333334, 10.0, 5.714285714285714, 10.666666666666666, 12.5],\n",
    "             \"baseline_Electronics_perc\": [0.0, 20.0, 16.666666666666668, 15.0, 10.0, 25.0, 14.285714285714286, 13.75, 10.0, 18.0, 11.818181818181818, 15.833333333333334, 12.307692307692308, 15.714285714285714, 10.666666666666666, 9.375],\n",
    "             \"baseline_Home_and_Kitchen_perc\": [30.0, 10.0, 16.666666666666668, 22.5, 20.0, 10.0, 12.857142857142858, 20.0, 14.444444444444445, 16.0, 8.181818181818182, 12.5, 13.846153846153847, 7.857142857142857, 10.0, 9.375],\n",
    "             \"baseline_Sports_and_Outdoors_perc\": [0.0, 25.0, 6.666666666666667, 20.0, 26.0, 21.666666666666668, 20.0, 8.75, 17.77777777777778, 15.0, 11.818181818181818, 10.0, 10.0, 7.857142857142857, 5.333333333333333, 8.75],\n",
    "             \"baseline_avg_perc\": [8.0, 13.0, 12.000000000000002, 17.5, 15.6, 18.666666666666668, 15.142857142857144, 13.75, 14.222222222222223, 15.4, 12.727272727272728, 12.0, 11.23076923076923, 9.285714285714285, 8.933333333333334, 10.25],\n",
    "             \"baseline_Office_Products_step3\": [100.0, 20.0, 100.0, 66.66666666666667, 44.44444444444444, 71.42857142857143, 71.42857142857143, 52.63157894736842, 66.66666666666667, 83.33333333333333, 84.21052631578948, 48.148148148148145, 65.0, 56.52173913043478, 48.0, 48.648648648648646],\n",
    "             \"baseline_Movies_and_TV_step3\": [0, 50.0, 60.0, 80.0, 63.63636363636363, 70.58823529411765, 66.66666666666667, 64.70588235294117, 82.3529411764706, 65.0, 76.0, 56.52173913043478, 68.42105263157895, 88.88888888888889, 72.72727272727273, 58.8235294117647],\n",
    "             \"baseline_Electronics_step3\": [0, 80.0, 100.0, 50.0, 50.0, 71.42857142857143, 55.55555555555556, 68.75, 52.94117647058823, 48.648648648648646, 65.0, 55.88235294117647, 64.0, 64.70588235294117, 45.714285714285715, 55.55555555555556],\n",
    "             \"baseline_Home_and_Kitchen_step3\": [75.0, 100.0, 62.5, 75.0, 58.8235294117647, 66.66666666666667, 69.23076923076923, 76.19047619047619, 65.0, 64.0, 50.0, 68.18181818181819, 58.064516129032256, 39.285714285714285, 31.25, 39.473684210526315],\n",
    "             \"baseline_Sports_and_Outdoors_step3\": [0, 83.33333333333333, 100.0, 88.88888888888889, 92.85714285714286, 68.42105263157895, 66.66666666666667, 100.0, 80.0, 68.18181818181819, 61.904761904761905, 44.44444444444444, 54.166666666666664, 42.30769230769231, 26.666666666666668, 45.16129032258065],\n",
    "             \"baseline_avg_step3\": [35.0, 66.66666666666666, 84.5, 72.11111111111111, 61.952296069943124, 69.70661948990123, 65.90964590964592, 72.45558749815716, 69.39215686274511, 65.83276003276004, 67.42305764411029, 54.6357005692044, 61.93044708545558, 58.341983393134285, 44.87164502164502, 49.532541629815164],\n",
    "             \"baseline_Office_Products_f1\": [np.nan, np.nan, 0.3333333333333333, 0.25, np.nan, 0.10000000000000002, 0.3, 0.10000000000000002, np.nan, 0.20000000000000004, 0.125, 0.23076923076923078, 0.07692307692307693, np.nan, 0.16666666666666666, 0.1111111111111111],\n",
    "             \"baseline_Movies_and_TV_f1\": [np.nan, np.nan, np.nan, 0.125, 0.2857142857142857, 0.16666666666666666, np.nan, 0.2727272727272727, 0.07142857142857142, 0.15384615384615385, 0.05263157894736842, np.nan, np.nan, np.nan, 0.0625, 0.15],\n",
    "             \"baseline_Electronics_f1\": [np.nan, 0.25, np.nan, np.nan, np.nan, 0.26666666666666666, 0.20000000000000004, 0.18181818181818182, 0.2222222222222222, 0.2222222222222222, np.nan, 0.3157894736842105, 0.1875, 0.22727272727272727, 0.375, 0.06666666666666667],\n",
    "             \"baseline_Home_and_Kitchen_f1\": [0.3333333333333333, np.nan, np.nan, np.nan, 0.5, 0.16666666666666666, 0.1111111111111111, 0.25, 0.07692307692307693, 0.25, np.nan, np.nan, 0.2777777777777778, 0.2727272727272727, np.nan, np.nan],\n",
    "             \"baseline_Sports_and_Outdoors_f1\": [np.nan, 0.20000000000000004, np.nan, 0.125, 0.3076923076923077, 0.3076923076923077, 0.42857142857142855, 0.14285714285714285, 0.0625, 0.20000000000000004, np.nan, 0.16666666666666666, 0.07692307692307693, 0.09090909090909091, np.nan, 0.07142857142857142],\n",
    "             \"baseline_avg_f1\": [0.3333333333333333, 0.22500000000000003, 0.3333333333333333, 0.16666666666666666, 0.3644688644688645, 0.20153846153846153, 0.25992063492063494, 0.1894805194805195, 0.10826846764346763, 0.20521367521367523, 0.08881578947368421, 0.2377417903733693, 0.1547809829059829, 0.196969696969697, 0.20138888888888887, 0.09980158730158728],\n",
    "             \"baseline_Office_Products_f1_r\": [np.nan, 0.5, 0.3333333333333333, 0.3333333333333333, 0.25000000000000006, 0.24999999999999997, 0.19047619047619044, 0.16071428571428573, 0.14285714285714285, 0.14285714285714285, 0.1090909090909091, 0.1388888888888889, 0.12307692307692308, 0.11904761904761903, 0.11111111111111112, 0.09375, 0.11764705882352941, 0.1111111111111111],\n",
    "             \"baseline_Movies_and_TV_f1_r\": [np.nan, 0.5, 0.3333333333333333, 0.3333333333333333, 0.2571428571428572, 0.2708333333333333, 0.20779220779220778, 0.16666666666666666, 0.1574074074074074, 0.15000000000000002, 0.12727272727272726, 0.13333333333333333, 0.11538461538461539, 0.09523809523809522, 0.09333333333333334, 0.078125, 0.0784313725490196, 0.07407407407407407, 0.07894736842105263, 0.15],\n",
    "             \"baseline_Electronics_f1_r\": [1.0, 0.5, 0.3333333333333333, 0.28125, 0.23636363636363644, 0.24358974358974356, 0.20535714285714282, 0.18055555555555555, 0.17283950617283952, 0.16315789473684217, 0.14204545454545453, 0.14999999999999997, 0.15384615384615385, 0.15384615384615383, 0.1611111111111111, 0.1736111111111111, 0.16666666666666666, 0.15740740740740738, 0.15789473684210525, 0.15, 0.19047619047619047, 0.22727272727272727],\n",
    "             \"baseline_Home_and_Kitchen_f1_r\": [1.0, 0.5625, 0.3611111111111111, 0.29545454545454547, 0.25333333333333347, 0.2647058823529411, 0.22556390977443608, 0.19318181818181818, 0.17874396135265702, 0.17826086956521742, 0.1590909090909091, 0.15789473684210525, 0.16599190283400814, 0.16964285714285712, 0.17777777777777776, 0.19270833333333334, 0.17647058823529413, 0.1746031746031746, 0.15789473684210525, 0.15, 0.19047619047619047, 0.22727272727272727],\n",
    "             \"baseline_Sports_and_Outdoors_f1_r\": [1.0, 0.5625, 0.3571428571428571, 0.2857142857142857, 0.24210526315789485, 0.24242424242424246, 0.2114285714285715, 0.1875, 0.1762452107279693, 0.17096774193548384, 0.15259740259740256, 0.15705128205128205, 0.1784615384615385, 0.17142857142857143, 0.17254901960784316, 0.18269230769230768, 0.17647058823529413, 0.1746031746031746, 0.15789473684210525, 0.15, 0.19047619047619047, 0.22727272727272727],\n",
    "             \"baseline_avg_f1_r\": [1.0, 0.5625, 0.3571428571428571, 0.2857142857142857, 0.24210526315789485, 0.24242424242424246, 0.2114285714285715, 0.1875, 0.1762452107279693, 0.17096774193548384, 0.15259740259740256, 0.15705128205128205, 0.1784615384615385, 0.17142857142857143, 0.17254901960784316, 0.18269230769230768, 0.17647058823529413, 0.1746031746031746, 0.15789473684210525, 0.15, 0.19047619047619047, 0.22727272727272727],\n",
    "             \"baseline_Office_Products_jacc\": [0.0, 0.0, 0.2, 0.14285714285714285, 0.0, 0.05263157894736842, 0.17647058823529413, 0.05263157894736842, 0.0, 0.1111111111111111, 0.06666666666666667, 0.13043478260869565, 0.04, 0.0, 0.09090909090909091, 0.058823529411764705],\n",
    "             \"baseline_Movies_and_TV_jacc\": [0, 0.0, 0.0, 0.06666666666666667, 0.16666666666666666, 0.09090909090909091, 0.0, 0.15789473684210525, 0.037037037037037035, 0.08333333333333333, 0.02702702702702703, 0.0, 0.0, 0.0, 0.03225806451612903, 0.08108108108108109],\n",
    "             \"baseline_Electronics_jacc\": [0, 0.14285714285714285, 0.0, 0.0, 0.0, 0.15384615384615385, 0.1111111111111111, 0.1, 0.125, 0.09090909090909091, 0.0, 0.1875, 0.10344827586206896, 0.1282051282051282, 0.23076923076923078, 0.034482758620689655],\n",
    "             \"baseline_Home_and_Kitchen_jacc\": [0.2, 0.0, 0.0, 0.0, 0.3333333333333333, 0.09090909090909091, 0.058823529411764705, 0.14285714285714285, 0.04, 0.14285714285714285, 0.0, 0.0, 0.16129032258064516, 0.15789473684210525, 0.0, 0.0],\n",
    "             \"baseline_Sports_and_Outdoors_jacc\": [0, 0.1111111111111111, 0.0, 0.06666666666666667, 0.18181818181818182, 0.18181818181818182, 0.2727272727272727, 0.07692307692307693, 0.03225806451612903, 0.15384615384615385, 0.0, 0.09090909090909091, 0.04, 0.047619047619047616, 0.0, 0.037037037037037035],\n",
    "             \"baseline_avg_jacc\": [0.04, 0.050793650793650794, 0.04, 0.05523809523809523, 0.13636363636363638, 0.11402281928597717, 0.12382650029708853, 0.10606130711393869, 0.046859020310633215, 0.1164113664113664, 0.018738738738738738, 0.08176877470355733, 0.06894771968854282, 0.06674378253325622, 0.07078727723889014, 0.0422848812301145],\n",
    "             \"baseline_Office_Products_jacc_r\": [0.0, 0.07142857142857142, 0.042857142857142864, 0.04761904761904762, 0.053030303030303025, 0.05289256198347108, 0.05827505827505827, 0.056277056277056266, 0.04946524064171123, 0.05006723582574976, 0.036309523809523805, 0.056888763410502544, 0.055628019323671486, 0.06469135802469135, 0.06002554278416348, 0.04946236559139785, 0.0625, 0.058823529411764705, np.nan, np.nan, np.nan, np.nan],\n",
    "             \"baseline_Movies_and_TV_jacc_r\": [0.0, 0.0, 0.0, 0.0, 0.03632478632478632, 0.05501165501165502, 0.05155101308947462, 0.04145299145299145, 0.05014705882352941, 0.04454764361885105, 0.044527986633249785, 0.03359683794466403, 0.023333333333333334, 0.027777777777777776, 0.022988505747126436, 0.02150537634408602, 0.030303030303030304, 0.02857142857142857, 0.04129129129129129, 0.08108108108108109, np.nan, np.nan],\n",
    "             \"baseline_Electronics_jacc_r\": [0.13333333333333333, 0.08888888888888888, 0.06666666666666667, 0.04761904761904761, 0.031746031746031744, 0.04696969696969697, 0.05128205128205128, 0.06513486513486512, 0.06831550802139037, 0.07261781905744753, 0.06145920356446672, 0.06980519480519481, 0.09800889328063242, 0.11584045584045584, 0.12507262852090437, 0.14525984870812456, 0.1359447004608295, 0.1272727272727273, 0.13660714285714287, 0.08108108108108109, 0.10526315789473684, 0.1282051282051282],\n",
    "             \"baseline_Home_and_Kitchen_jacc_r\": [0.0, 0.0625, 0.07333333333333332, 0.04421768707482993, 0.05442176870748299, 0.06783216783216783, 0.053632478632478636, 0.05079365079365079, 0.04893207282913165, 0.06757634827810266, 0.0659670008354219, 0.06140195208518189, 0.06956709956709957, 0.06837606837606837, 0.0698005698005698, 0.14285714285714285, 0.13333333333333333, 0.16129032258064516, np.nan, np.nan, np.nan, np.nan],\n",
    "             \"baseline_Sports_and_Outdoors_jacc_r\": [0.0, 0.0, 0.028571428571428574, 0.04081632653061224, 0.03968253968253969, 0.03496503496503497, 0.04240631163708087, 0.046031746031746035, 0.05602941176470588, 0.06618507051943583, 0.05959899749373434, 0.06593889202584854, 0.09563311688311689, 0.10593110593110593, 0.09416445623342176, 0.03225806451612903, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "             \"baseline_avg_jacc_r\": [0.025974025974025976, 0.04504504504504504, 0.04305555555555556, 0.03657694962042787, 0.0426887926887927, 0.05156402737047897, 0.051169386169386176, 0.05163572060123786, 0.0545284780578898, 0.059848641210870336, 0.05382015645173539, 0.05763975155279503, 0.07036686743208483, 0.08125205041871708, 0.0824610893576411, 0.09646925691737386, 0.09489621361741177, 0.09415355585049269, 0.08894921707421707, 0.08108108108108109, 0.10526315789473684, 0.1282051282051282],\n",
    "             \"baseline_Office_Products_rbo\": [0, 0, 0.27777777777777773, 0.2708333333333333, 0.0, 0.03361111111111111, 0.15912698412698412, 0.047896825396825396, 0.0, 0.2627479927479927, 0.0321412962037962, 0.12825486479332635, 0.056164135010288864, 0.0, 0.013888888888888888, 0.08478632387946113],\n",
    "             \"baseline_Movies_and_TV_rbo\": [np.nan, 0, 0.0, 0.015625, 0.14557823129251699, 0.09193422318422319, 0.0, 0.21905745769382132, 0.00510204081632653, 0.10454438723669493, 0.00879003494287835, 0.0, 0.0, 0.0, 0.05817056207681208, 0.05162570466169536],\n",
    "             \"baseline_Electronics_rbo\": [np.nan, 0.14583333333333331, 0.0, 0.0, 0.0, 0.29546472046472044, 0.043611111111111114, 0.20098058507149413, 0.1027336860670194, 0.08311263446067368, 0.0, 0.29516204221068154, 0.2778824474136974, 0.0959345438078199, 0.0717433608058608, 0.014334554334554335],\n",
    "             \"baseline_Home_and_Kitchen_rbo\": [0.1111111111111111, 0.0, 0.0, 0.0, 0.5449206349206349, 0.061111111111111116, 0.14766313932980596, 0.13238462925962927, 0.019320423166577012, 0.22603091353091354, 0.0, 0.0, 0.07461714030341482, 0.055348943985307625, 0.0, 0.0] ,\n",
    "             \"baseline_Sports_and_Outdoors_rbo\": [np.nan, 0.15666666666666665, 0.0, 0.11056547619047619, 0.05117446655908194, 0.09314638353099894, 0.16872175443604012, 0.07278911564625849, 0.049241990648240655, 0.16576386576386576, 0.0, 0.05496632996632997, 0.12924105808721192, 0.017355371900826446, 0.0, 0.00510204081632653],\n",
    "             \"baseline_avg_rbo\": [0.05555555555555555, 0.0605, 0.055555555555555546, 0.0794047619047619, 0.14833466655444677, 0.11505350988043295, 0.10382459780078826, 0.13462172261360572, 0.03527962813963272, 0.16843995874802814, 0.00818626622933491, 0.09567664739406759, 0.1075809561629226, 0.0337277719387908, 0.028760562354312354, 0.031169724738407466],\n",
    "             \"baseline_Office_Products_rbo_p\": [0.009062508736163042, 0.0175005345326608, 0.02531810634941796, 0.032527045550999854, 0.039138053085571514, 0.045089416123066293, 0.04994887632329356, 0.051824211185751895, 0.0435649665008104, 0.0854518458293616],\n",
    "             \"baseline_Movies_and_TV_rbo_p\": [0.06250522600698004, 0.06258702237607584, 0.06295582943650448, 0.06397892783234518, 0.0661642895603129, 0.0700652306996611, 0.07595394769706017, 0.08280773595231086, 0.08515387849088936, 0.10627672761906054],\n",
    "             \"baseline_Electronics_rbo_p\": [0.1872629391106494, 0.18641754378097433, 0.1847280577987131, 0.18193490501779555, 0.1777947478984305, 0.17213271967186453, 0.16483676957376753, 0.15515923961291275, 0.13618571080293437, 0.1641745636925604],\n",
    "             \"baseline_Home_and_Kitchen_rbo_p\": [0.006626312499337584, 0.013854665899093146, 0.02148126314524937, 0.02931902244674997, 0.037164104182771565, 0.04471892163256059, 0.051356051097083966, 0.05514892382612073, 0.048539075644335634, 0.08578175291990658],\n",
    "             \"baseline_Sports_and_Outdoors_rbo_p\": [0.06293740626182351, 0.06433067238136013, 0.06679498632863781, 0.07043844460085256, 0.07537246412171786, 0.08171339188556707, 0.08941966401994875, 0.0972276305652317, 0.09801649752383955, 0.12967090751327023],\n",
    "             \"baseline_avg_rbo_p\": [0.06567887852299072, 0.06893808779403282, 0.0722556486117045, 0.07563966908974859, 0.07912673176976086, 0.08274393600254391, 0.08630306174223079, 0.08843354822846558, 0.08229202579256187, 0.11427115951483191],\n",
    "             \"baseline_Office_Products_rbo_r\": [0.0854518458293616, 0.09765925237641326, 0.09765925237641326, 0.08380398119169293, 0.07441985655987952, 0.07441985655987952, 0.07441985655987952, 0.07441985655987952, 0.07441985655987952, 0.07441985655987952, 0.07224793769046928, 0.07224793769046928, 0.09401576877247754, 0.12655853761041666, 0.12655853761041666, 0.058463810041628664, 0.08478632387946113, 0.08478632387946113, np.nan, np.nan, np.nan, np.nan],\n",
    "             \"baseline_Movies_and_TV_rbo_r\": [0.04669517612699792, 0.050030545850354914, 0.050030545850354914, 0.05387904937730529, 0.05387904937730529, 0.05387904937730529, 0.05387904937730529, 0.04623745088437098, 0.05392244106124518, 0.05392244106124518, 0.05991382340138353, 0.04002086911482881, 0.03260467567634389, 0.03092208562442808, 0.03952876722712859, 0.03952876722712859, 0.030207869802286853, 0.030207869802286853, 0.030207869802286853, 0.05162570466169536, np.nan, np.nan],\n",
    "             \"baseline_Electronics_rbo_r\": [0.10845286793873107, 0.10845286793873107, 0.10845286793873107, 0.10845286793873107, 0.10578283469625947, 0.12341330714563604, 0.13463269870433023, 0.13463269870433023, 0.13463269870433023, 0.13782259996806132, 0.14829054317438914, 0.141704287937251, 0.141704287937251, 0.16194775764257258, 0.16194775764257258, 0.16476700573974665, 0.15806974015972505, 0.15806974015972505, 0.19554829300925072, 0.0959345438078199, 0.0959345438078199, 0.0959345438078199],\n",
    "             \"baseline_Home_and_Kitchen_rbo_r\": [0.08578175291990658, 0.08578175291990658, 0.09150053644790036, 0.09009978111481387, 0.09009978111481387, 0.09703053350826109, 0.10002381870802358, 0.10002381870802358, 0.10002381870802358, 0.11695807612960857, 0.06346275628073028, 0.06462187232293351, 0.06462187232293351, 0.07217211384899293, 0.07217211384899293, 0.14434422769798586, 0.07461714030341482, 0.07461714030341482, np.nan, np.nan, np.nan, np.nan],\n",
    "             \"baseline_Sports_and_Outdoors_rbo_r\": [0.0716489680141549, 0.0716489680141549, 0.07676675144373739, 0.07676675144373739, 0.07676675144373739, 0.0706206041188967, 0.0706206041188967, 0.07043989482494988, 0.07347132617089223, 0.07347132617089223, 0.07347132617089223, 0.07970643220089954, 0.08279894498022072, 0.09720741291611827, 0.1075029282060532, 0.049241990648240655, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "             \"baseline_avg_rbo_r\": [0.07976224365177337, 0.08299584812414255, 0.08530128834981318, 0.08337396916373423, 0.08085056372168176, 0.08353984740265047, 0.0853059904642203, 0.08448262208473176, 0.08840373342081419, 0.09046809558654281, 0.08395995710591984, 0.08003739385022558, 0.08446406422137724, 0.10245252473272504, 0.10856832178650991, 0.11011597315754106, 0.09914691775237497, 0.09914691775237497, 0.11287808140576878, 0.07378012423475763, 0.0959345438078199, 0.0959345438078199],\n",
    "             \"baseline_Office_Products_rel\": [0.4240944648399856, 0.2895330120717931, 0.3034916170605498, 0.40407353072488894, 0.3343016210369692, 0.3275185330399267, 0.3612450575533287, 0.4024558561326922, 0.4581968708522308, 0.30381246395757233, 0.411747767105929, 0.5311566997624309, 0.41570138681301594, 0.3834879721088172, 0.4228835485726184, 0.45152868945367364],\n",
    "             \"baseline_Movies_and_TV_rel\": [np.nan, 0.19747638020965824, 0.31445896990963357, 0.40424891037842126, 0.30917048071398734, 0.423968806972335, 0.36210432023476835, 0.3855991451899197, 0.3105519821529074, 0.47194140319382477, 0.43604072268937033, 0.3460987521756126, 0.5028091776829001, 0.4634425273888975, 0.2719485884333184, 0.40126657632439616],\n",
    "             \"baseline_Electronics_rel\": [np.nan, 0.2870921513392014, 0.39966737863780144, 0.2237866235604523, 0.4639428945290107, 0.5393753477798376, 0.41644900041592664, 0.47509511102703056, 0.4721372487860427, 0.5612166611081281, 0.5153737903656453, 0.6471999035209182, 0.4641087221074634, 0.4532820419229324, 0.5081766842015174, 0.4870959439074875],\n",
    "             \"baseline_Home_and_Kitchen_rel\": [0.38801756860138575, 0.21587714185047824, 0.22224576461939632, 0.2540186431668052, 0.5170130746791557, 0.416825705865193, 0.45022991511893845, 0.3284339601294815, 0.44307810227685795, 0.44203607970543907, 0.4801019895578649, 0.40796233374028196, 0.5382560582042318, 0.603334560101057, 0.2966276361050187, 0.565766992462644],\n",
    "             \"baseline_Sports_and_Outdoors_rel\": [np.nan, 0.25710486334250937, 0.12462050560285735, 0.4131750818419191, 0.34927564684249085, 0.4094132792676281, 0.42921399635470314, 0.25500105664902534, 0.22534439440541779, 0.46559145971869165, 0.3785783963371688, 0.5536401020212464, 0.4468498107265464, 0.47316266985897265, 0.2724970430358169, 0.41723879748446074],\n",
    "             \"baseline_avg_rel\": [0.4060560167206857, 0.24941670976272806, 0.2728968471660477, 0.3398605579344974, 0.3947407435603228, 0.4234203345849841, 0.40384845793553303, 0.36931702582562986, 0.38186171969469135, 0.44891961353673115, 0.4443685332111957, 0.49721155824409796, 0.4735450311068316, 0.47534195427613535, 0.35442670006965793, 0.4645793999265324]\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_evaluation():\n",
    "\n",
    "    results = pd.read_csv(f'{path}/results.txt', sep='\\n', header=None)\n",
    "\n",
    "    step3_len = evaluate_clustering_and_time(results)\n",
    "\n",
    "    evaluate_ranking(step3_len)\n",
    "    \n",
    "    evaluate_test_specifics(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clustering_and_time(results):\n",
    "    cat = [cat[2] for cat in results[results[0].str.contains(\"Category:\")][0].str.split(\" \")][0]\n",
    "    asin = [asin[2] for asin in results[results[0].str.contains(\"Found asin_id:\")][0].str.split(\" \")][0]\n",
    "    size = [size[4] for size in results[results[0].str.contains(\"Chosen product:\")][0].str.split(\" \")][0]\n",
    "\n",
    "    time = [time[1] for time in results[results[0].str.contains(\"seconds\")][0].str.split(\" \")][0]\n",
    "    clustered = [clus[-1] for clus in results[results[0].str.contains(\"mean:\")][0].str.split(\" \")][0]\n",
    "\n",
    "    clust_cat.append(100-float(clustered))\n",
    "    run_cat.append(float(time))\n",
    "    \n",
    "    step3_len = len(results[results[0].str.contains(\"\\t\\tstep 3\")])\n",
    "\n",
    "    print(f'-----{cat} {asin} {size}-----', file=f)\n",
    "    \n",
    "    return step3_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ranking(step3_len):\n",
    "    all_files = sorted(glob.glob(f'{path}/*.csv'))\n",
    "\n",
    "    ranking = pd.read_csv(all_files[0], sep=';').drop_duplicates('review')\n",
    "    ground_truth = pd.read_csv(all_files[1], sep=';', index_col=0)\n",
    "\n",
    "    ranking['Model ranking'] = ranking['Model ranking'] + 1\n",
    "\n",
    "    print(f\"\\nLength of final ranking:\\n{len(ranking)}\\n\", file=f)\n",
    "\n",
    "    len_ranking_cat.append(len(ranking))\n",
    "    perc_ranking_cat.append(100*len(ranking)/nr_rev)\n",
    "    if step3_len > 0:\n",
    "        perc_step3_cat.append(100*len(ranking)/step3_len)\n",
    "    else:\n",
    "        perc_step3_cat.append(0)\n",
    "\n",
    "    f1_score(ranking, ground_truth)\n",
    "    \n",
    "    jaccard_similarity(ranking)\n",
    "    \n",
    "    rbo_score(ranking)\n",
    "    \n",
    "    rel_cat.append(ranking['relevance'].mean(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(ranking, ground_truth):\n",
    "    \n",
    "    if len(ranking) == 0:\n",
    "        f1_r_nr_rev.append(np.nan)\n",
    "        f1_nr_rev_cat.append(np.nan)\n",
    "    else:\n",
    "        F1_score = np.nan\n",
    "\n",
    "        for r in range(1,len(ranking)+1):\n",
    "            TP = 0\n",
    "            TN = 0\n",
    "            FP = 0\n",
    "            FN = 0\n",
    "\n",
    "            for elem in ranking['ranking'][:r]:\n",
    "                if elem in range(1,len(ranking[:r])+1):\n",
    "                    TP +=1\n",
    "                else:\n",
    "                    FP +=1\n",
    "\n",
    "            for elem in ground_truth[~ground_truth.ranking.isin(list(ranking['ranking'][:r]))]['ranking']:\n",
    "                if elem in range(1,len(ranking[:r])+1):\n",
    "                    FN +=1\n",
    "                else:\n",
    "                    TN +=1\n",
    "\n",
    "            print(f\"For r={r}\\n\\tTP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\", file=f)\n",
    "\n",
    "            accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "            precision = TP/(TP+FP)\n",
    "            recall = TP/(TP+FN)\n",
    "\n",
    "            if precision+recall > 0:\n",
    "                F1_score = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "            print(f\"\\tacc: {accuracy}, pre: {precision}, rec: {recall}, F1: {F1_score}\\n\", file=f)\n",
    "            f1_r_nr_rev.append(F1_score)\n",
    "\n",
    "\n",
    "        f1_nr_rev_cat.append(F1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(ranking):\n",
    "    \n",
    "    if len(ranking) == 0:\n",
    "        jacc_r_nr_rev.append(np.nan)\n",
    "        jacc_nr_rev_cat.append(np.nan)\n",
    "    else:\n",
    "        similarity = 0\n",
    "\n",
    "        for r in range(1,len(ranking)+1):\n",
    "            A = set(ranking['ranking'][:r])\n",
    "            B = set(ranking['Model ranking'][:r])\n",
    "\n",
    "            #Find intersection of two sets\n",
    "            nominator = A.intersection(B)\n",
    "\n",
    "            #Find union of two sets\n",
    "            denominator = A.union(B)\n",
    "\n",
    "            #Take the ratio of sizes\n",
    "            if len(denominator) > 0:\n",
    "                similarity = len(nominator)/len(denominator)\n",
    "\n",
    "            jacc_r_nr_rev.append(similarity)\n",
    "\n",
    "        jacc_nr_rev_cat.append(similarity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbo_score(ranking):\n",
    "    \n",
    "    if len(ranking) == 0:\n",
    "        rbo_p_nr_rev.append(np.nan)\n",
    "        rbo_r_nr_rev.append(np.nan)\n",
    "        rbo_nr_rev_cat.append(np.nan)\n",
    "    else:\n",
    "        # rbo with fluctuating p\n",
    "        for p in range(1,11):\n",
    "            rbo_p_nr_rev.append(rbo.RankingSimilarity(list(ranking['Model ranking']), list(ranking['ranking'])).rbo(p=p/10))\n",
    "\n",
    "        rbo_score = np.nan\n",
    "\n",
    "        # rbo with fluctuating r, p=1 (no weight)\n",
    "        for r in range(1,len(ranking)+1):\n",
    "            rbo_score = rbo.RankingSimilarity(list(ranking['Model ranking']), list(ranking['ranking'])).rbo()\n",
    "            rbo_r_nr_rev.append(rbo_score)\n",
    "\n",
    "        rbo_nr_rev_cat.append(rbo_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test_specifics(results):\n",
    "    rem_found = results[results[0].str.contains(\"reviews removed from the relevance model\")]\n",
    "    \n",
    "    if len(rem_found) == 0:\n",
    "        removed_cat.append(np.nan)\n",
    "        size_cat.append(np.nan)\n",
    "    else:\n",
    "        rem = [rem[0] for rem in rem_found[0].str.split(\" \")][0] \n",
    "        size = float([size[-1] for size in results[results[0].str.contains(\"It now has size:\")][0].str.split(\" \")][0])\n",
    "\n",
    "        removed_cat.append(float(rem.replace(\"\\t\\t\",\"\")))\n",
    "        size_cat.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clust_run(clust, run, to_plot):\n",
    "    \n",
    "    if to_plot == \"category\":\n",
    "    \n",
    "        # individual categories\n",
    "        y1 = clust.mean(axis=0)\n",
    "        y2 = run.mean(axis=0)\n",
    "        fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        line1, = ax1.plot(cols, y1, color=colors[1], marker='o', label=\"%cluster\")\n",
    "        line2, = ax2.plot(cols, y2, color=colors[2], marker='x', label=\"run time\")\n",
    "        \n",
    "        line1a, = ax1.plot(cols, baselines[f\"baseline_{category}_clust\"], linestyle=':', color=colors[1], alpha=0.5, marker='o', label=\"baseline %cluster\", visible=baseline)\n",
    "        line2a, = ax2.plot(cols, baselines[f\"baseline_{category}_run\"], linestyle=':', color=colors[2], alpha=0.5, marker='x', label=\"baseline run time\", visible=baseline)\n",
    "\n",
    "        ax1.set_xlabel('Number of reviews', fontsize=15)\n",
    "        ax1.set_ylabel('% of clustered reviews', color=colors[1], fontsize=15)\n",
    "        ax2.set_ylabel('Runtime in seconds', color=colors[2], fontsize=15)\n",
    "        ax1.set_xticks(cols)\n",
    "        ax2.set_xticks(cols)\n",
    "        if baseline:\n",
    "            ax1.legend(handles=[line1, line1a, line2, line2a], loc=2)\n",
    "        else:\n",
    "            ax1.legend(handles=[line1, line2], loc=2)\n",
    "        ax2.set_title(f\"{question}_{test}: Cluster percentage & run time for {category}\", fontsize=20)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/individual_clust_run_{category}.pdf')\n",
    "    \n",
    "    elif to_plot == \"all\":\n",
    "        # clust + run average\n",
    "        y1 = clust.mean(axis=0)\n",
    "        y2 = run.mean(axis=0)\n",
    "        fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        line1, = ax1.plot(cols, y1, color=colors[1], marker='o', label=\"%cluster\")\n",
    "        line2, = ax2.plot(cols, y2, color=colors[2], marker='x', label=\"run time\")\n",
    "        \n",
    "        line1a, = ax1.plot(cols, baselines[\"baseline_avg_clust\"], linestyle=':', color=colors[1], alpha=0.5, marker='o', label=\"baseline %cluster\", visible=baseline)\n",
    "        line2a, = ax2.plot(cols, baselines[\"baseline_avg_run\"], linestyle=':', color=colors[2], alpha=0.5, marker='x', label=\"baseline run time\", visible=baseline)\n",
    "\n",
    "        ax1.set_xlabel('Number of reviews', fontsize=15)\n",
    "        ax1.set_ylabel('% of clustered reviews', color=colors[1], fontsize=15)\n",
    "        ax2.set_ylabel('Runtime in seconds', color=colors[2], fontsize=15)\n",
    "        ax1.set_xticks(cols)\n",
    "        ax2.set_xticks(cols)\n",
    "        if baseline:\n",
    "            ax1.legend(handles=[line1, line1a, line2, line2a], loc=2)\n",
    "        else:\n",
    "            ax1.legend(handles=[line1, line2], loc=2)\n",
    "        ax2.set_title(f\"{question}_{test}: Average cluster percentage & run time\", fontsize=20) #, {test}')\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/clust_run_all.pdf')\n",
    "            \n",
    "        # clust + run stdev\n",
    "        y1 = clust.mean(axis=0)\n",
    "        y2 = run.mean(axis=0)\n",
    "        fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        line1, = ax1.plot(cols, y1, color=colors[1], marker='o', label=\"%cluster\")\n",
    "        line2, = ax2.plot(cols, y2, color=colors[2], marker='x', label=\"run time\")\n",
    "        \n",
    "        line1a, = ax1.plot(cols, baselines[\"baseline_avg_clust\"], linestyle=':', color=colors[1], alpha=0.5, marker='o', label=\"baseline %cluster\", visible=baseline)\n",
    "        line2a, = ax2.plot(cols, baselines[\"baseline_avg_run\"], linestyle=':', color=colors[2], alpha=0.5, marker='x', label=\"baseline run time\", visible=baseline)\n",
    "\n",
    "        ax1.fill_between(cols, y1+clust.std(axis=0), y1-clust.std(axis=0), color=colors[8], alpha=0.3)\n",
    "        ax2.fill_between(cols, y2+run.std(axis=0), y2-run.std(axis=0), color=colors[3], alpha=0.3)\n",
    "\n",
    "        ax1.set_xlabel('Number of reviews', fontsize=15)\n",
    "        ax1.set_ylabel('% of clustered reviews', color=colors[1], fontsize=15)\n",
    "        ax2.set_ylabel('Runtime in seconds', color=colors[2], fontsize=15)\n",
    "        ax1.set_xticks(cols)\n",
    "        ax2.set_xticks(cols)\n",
    "        if baseline:\n",
    "            ax1.legend(handles=[line1, line1a, line2, line2a], loc=2)\n",
    "        else:\n",
    "            ax1.legend(handles=[line1, line2], loc=2)\n",
    "        ax2.set_title(f\"{question}_{test}: Average cluster percentage & run time with their standard deviations\", fontsize=20) #, {test}')\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/clust_run_all_stdev.pdf')\n",
    "\n",
    "        # clust + category lines\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('% of clustered reviews', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Cluster percentages\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, clust.mean(axis=0), color=colors[1], marker='o', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_clust\"], linestyle=':', color=colors[1], alpha=0.5, marker='o', label=\"baseline\", visible=baseline)\n",
    "        for i in range(len(clust)):\n",
    "            plt.plot(cols, list(clust.loc[i,:]), linestyle='--', color=colors[i+2], label=categories[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/clust_categories_all.pdf')\n",
    "\n",
    "        # run + category lines\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Runtime in seconds', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Runtimes\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, run.mean(axis=0), color=colors[2], marker='x', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_run\"], linestyle=':', color=colors[2], alpha=0.5, marker='x', label=\"baseline\", visible=baseline)\n",
    "        for i in range(len(run)):\n",
    "            plt.plot(cols, list(run.loc[i,:]), linestyle='--', color=colors[i+2], label=categories[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/run_categories_all.pdf')\n",
    "        \n",
    "        # clust + stdev\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('% of clustered reviews', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Cluster percentage with its standard deviation\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, clust.mean(axis=0), color=colors[1], marker='o', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_clust\"], linestyle=':', color=colors[1], alpha=0.5, marker='o', label=\"baseline\", visible=baseline)\n",
    "        plt.fill_between(cols, clust.mean(axis=0)+clust.std(axis=0), clust.mean(axis=0)-clust.std(axis=0), color=colors[8], alpha=0.3)\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/clust_stdev_all.pdf')\n",
    "\n",
    "        # run + stdev\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Runtime in seconds', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Runtime with its standard deviation\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, run.mean(axis=0), color=colors[2], marker='x', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_run\"], linestyle=':', color=colors[2], alpha=0.5, marker='x', label=\"baseline\", visible=baseline)\n",
    "        plt.fill_between(cols, run.mean(axis=0)+run.std(axis=0), run.mean(axis=0)-run.std(axis=0), color=colors[3], alpha=0.3)\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/run_stdev_all.pdf')\n",
    "            \n",
    "    elif to_plot == \"tests\":\n",
    "        \n",
    "        # clust + all tests\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('% of clustered reviews', fontsize=15)\n",
    "        plt.title(f\"{question}: Cluster percentages\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, clust.mean(axis=0), color=colors[1], marker='o', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_clust\"], linestyle=':', color=colors[1], alpha=0.5, marker='o', label=\"baseline\", visible=baseline)\n",
    "        for i in range(1,len(tests)+1):\n",
    "            plt.plot(cols, list(clust.iloc[(len(categories)*i-len(categories)):len(categories)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=tests[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/clust_tests.pdf')\n",
    "\n",
    "        # run + all tests\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Runtime in seconds', fontsize=15)\n",
    "        plt.title(f\"{question}: Runtimes\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, run.mean(axis=0), color=colors[2], marker='x', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_run\"], linestyle=':', color=colors[2], alpha=0.5, marker='x', label=\"baseline\", visible=baseline)\n",
    "        for i in range(1,len(tests)+1):\n",
    "            plt.plot(cols, list(run.iloc[(len(categories)*i-len(categories)):len(categories)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=tests[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/run_tests.pdf')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ranking(data_len, data_perc, data_step3, to_plot):\n",
    "    \n",
    "    if to_plot == \"\":\n",
    "        # len + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Number of reviews in final ranking', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Number of reviews\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, data_len.mean(axis=0), color=colors[1], marker='o', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_ranksize\"], linestyle=':', color=colors[1], alpha=0.5, marker='o', label=\"baseline\", visible=baseline)\n",
    "        for i in range(len(data_len)):\n",
    "            plt.plot(cols, list(data_len.loc[i,:]), linestyle='--', color=colors[i+3], label=categories[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/len_categories.pdf')\n",
    "\n",
    "        # perc + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Percentage of reviews in final ranking', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Percentage of reviews\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, data_perc.mean(axis=0), color=colors[2], marker='x', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_perc\"], linestyle=':', color=colors[2], alpha=0.5, marker='x', label=\"baseline\", visible=baseline)\n",
    "        for i in range(len(data_perc)):\n",
    "            plt.plot(cols, list(data_perc.loc[i,:]), linestyle='--', color=colors[i+3], label=categories[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/perc_categories.pdf')\n",
    "\n",
    "        # len + perc + stdev\n",
    "        y1 = data_len.mean(axis=0)\n",
    "        y2 = data_perc.mean(axis=0)\n",
    "        fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        line1, = ax1.plot(cols, y1, color=colors[1], marker='o', label=\"size\")\n",
    "        line2, = ax2.plot(cols, y2, color=colors[2], marker='x', label=\"%\")\n",
    "    \n",
    "        line1a, = ax1.plot(cols, baselines[\"baseline_avg_ranksize\"], linestyle=':', color=colors[1], alpha=0.5, marker='o', label=\"baseline size\", visible=baseline)\n",
    "        line2a, = ax2.plot(cols, baselines[\"baseline_avg_perc\"], linestyle=':', color=colors[2], alpha=0.5, marker='x', label=\"baseline %\", visible=baseline)\n",
    "\n",
    "        ax1.fill_between(cols, y1+data_len.std(axis=0), y1-data_len.std(axis=0), color=colors[8], alpha=0.3)\n",
    "        ax2.fill_between(cols, y2+data_perc.std(axis=0), y2-data_perc.std(axis=0), color=colors[3], alpha=0.3)\n",
    "\n",
    "        ax1.set_xlabel('Number of reviews', fontsize=15)\n",
    "        ax1.set_ylabel('Number of reviews in final ranking', color=colors[1], fontsize=15)\n",
    "        ax2.set_ylabel('Percentage of reviews in final ranking', color=colors[2], fontsize=15)\n",
    "        ax1.set_xticks(cols)\n",
    "        ax2.set_xticks(cols)\n",
    "        if baseline:\n",
    "            ax1.legend(handles=[line1, line1a, line2, line2a], loc=2)\n",
    "        else:\n",
    "            ax1.legend(handles=[line1, line2], loc=2)\n",
    "        ax2.set_title(f\"{question}_{test}: Number & percentage of reviews with their standard deviations\", fontsize=20) #, {test}')\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/len_perc_stdev.pdf')\n",
    "\n",
    "        # step3 + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Percentage of successful step 3s', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Percentage of successful step 3s\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, data_step3.mean(axis=0), color=colors[1], marker='o', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_step3\"], linestyle=':', color=colors[1], alpha=0.5, marker='o', label=\"baseline\", visible=baseline)\n",
    "        for i in range(len(data_step3)):\n",
    "            plt.plot(cols, list(data_step3.loc[i,:]), linestyle='--', color=colors[i+3], label=categories[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/step3_categories.pdf')\n",
    "\n",
    "        # step3 + stdev\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Percentage of successful step 3s', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Percentage of successful step 3s with its standard deviation\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, data_step3.mean(axis=0), color=colors[1], marker='o', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_step3\"], linestyle=':', color=colors[1], alpha=0.5, marker='o', label=\"baseline\", visible=baseline)\n",
    "        plt.fill_between(cols, data_step3.mean(axis=0)+data_step3.std(axis=0), data_step3.mean(axis=0)-data_step3.std(axis=0), color=colors[8], alpha=0.3)\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/step3_stdev.pdf')\n",
    "\n",
    "    elif to_plot == \"tests\":\n",
    "        # len + all tests\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Number of reviews in final ranking', fontsize=15)\n",
    "        plt.title(f\"{question}: Number of reviews\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, data_len.mean(axis=0), color=colors[1], marker='o', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_ranksize\"], linestyle=':', color=colors[1], alpha=0.5, marker='o', label=\"baseline\", visible=baseline)\n",
    "        for i in range(1,len(tests)+1):\n",
    "            plt.plot(cols, list(data_len.iloc[(len(categories)*i-len(categories)):len(categories)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=tests[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/len_tests.pdf')\n",
    "            \n",
    "        # perc + all tests\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Percentage of reviews in final ranking', fontsize=15)\n",
    "        plt.title(f\"{question}: Percentage of reviews\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, data_perc.mean(axis=0), color=colors[2], marker='x', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_perc\"], linestyle=':', color=colors[2], alpha=0.5, marker='x', label=\"baseline\", visible=baseline)\n",
    "        for i in range(1,len(tests)+1):\n",
    "            plt.plot(cols, list(data_perc.iloc[(len(categories)*i-len(categories)):len(categories)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=tests[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/perc_tests.pdf')\n",
    "        \n",
    "        # step3 + all tests\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Percentage of successful step 3s', fontsize=15)\n",
    "        plt.title(f\"{question}: Percentage of successful step 3s\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, data_step3.mean(axis=0), color=colors[1], marker='o', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_step3\"], linestyle=':', color=colors[1], alpha=0.5, marker='o', label=\"baseline\", visible=baseline)\n",
    "        for i in range(1,len(tests)+1):\n",
    "            plt.plot(cols, list(data_step3.iloc[(len(categories)*i-len(categories)):len(categories)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=tests[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/step3_tests.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(data_f1, data_jacc, data_rbo, to_plot):\n",
    "    \n",
    "    if to_plot == \"category\":\n",
    "        # individual categories with all metrics\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Metric scores', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Number of reviews with their performances for {category}\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, data_f1.mean(axis=0), color=colors[11], marker='o', label=\"F1\")\n",
    "        plt.plot(cols, data_jacc.mean(axis=0), color=colors[12], marker='x', label=\"Jaccard\")\n",
    "        plt.plot(cols, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"RBO\")\n",
    "        plt.plot(cols, baselines[f\"baseline_{category}_f1\"], linestyle=':', color=colors[11], alpha=0.5, marker='o', label=\"baseline F1\", visible=baseline)\n",
    "        plt.plot(cols, baselines[f\"baseline_{category}_jacc\"], linestyle=':', color=colors[12], alpha=0.5, marker='x', label=\"baseline Jaccard\", visible=baseline)\n",
    "        plt.plot(cols, baselines[f\"baseline_{category}_rbo\"], linestyle=':', color=colors[9], alpha=0.5, marker='s', label=\"baseline RBO\", visible=baseline)\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/individual_metrics_{category}.pdf')\n",
    "    \n",
    "    elif to_plot == \"all\":\n",
    "        # F1 + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('F1-score', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Number of reviews versus average F1 score\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, data_f1.mean(axis=0), color=colors[11], marker='o', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_f1\"], linestyle=':', color=colors[11], alpha=0.5, marker='o', label=\"baseline\", visible=baseline)\n",
    "        for i in range(len(data_f1)):\n",
    "            plt.plot(cols, list(data_f1.loc[i,:]), linestyle='--', color=colors[i+3], label=categories[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/F1_categories.pdf')\n",
    "\n",
    "        # Jaccard + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Jaccard similarity', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Number of reviews versus average Jaccard similarities\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, data_jacc.mean(axis=0), color=colors[12], marker='x', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_jacc\"], linestyle=':', color=colors[12], alpha=0.5, marker='x', label=\"baseline\", visible=baseline)\n",
    "        for i in range(len(data_jacc)):\n",
    "            plt.plot(cols, list(data_jacc.loc[i,:]), linestyle='--', color=colors[i+3], label=categories[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/Jacc_categories.pdf')\n",
    "\n",
    "        # RBO + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('RBO score', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Number of reviews versus average RBO score\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_rbo\"], linestyle=':', color=colors[9], alpha=0.5, marker='s', label=\"baseline\", visible=baseline)\n",
    "        for i in range(len(data_rbo)):\n",
    "            plt.plot(cols, list(data_rbo.loc[i,:]), linestyle='--', color=colors[i+3], label=categories[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/RBO_categories.pdf')\n",
    "\n",
    "        # all metrics\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Metric scores', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Number of reviews with their performances\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, data_f1.mean(axis=0), color=colors[11], marker='o', label=\"F1\")\n",
    "        plt.plot(cols, data_jacc.mean(axis=0), color=colors[12], marker='x', label=\"Jaccard\")\n",
    "        plt.plot(cols, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"RBO\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_f1\"], linestyle=':', color=colors[11], alpha=0.5, marker='o', label=\"baseline F1\", visible=baseline)\n",
    "        plt.plot(cols, baselines[\"baseline_avg_jacc\"], linestyle=':', color=colors[12], alpha=0.5, marker='x', label=\"baseline Jaccard\", visible=baseline)\n",
    "        plt.plot(cols, baselines[\"baseline_avg_rbo\"], linestyle=':', color=colors[9], alpha=0.5, marker='s', label=\"baseline RBO\", visible=baseline)\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/all_metrics.pdf')\n",
    "\n",
    "        # all metrics + stdev\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Metric scores', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Number of reviews with their performances with their standard deviations\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, data_f1.mean(axis=0), color=colors[11], marker='o', label=\"F1\")\n",
    "        plt.plot(cols, data_jacc.mean(axis=0), color=colors[12], marker='x', label=\"Jaccard\")\n",
    "        plt.plot(cols, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"RBO\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_f1\"], linestyle=':', color=colors[11], alpha=0.5, marker='o', label=\"baseline F1\", visible=baseline)\n",
    "        plt.plot(cols, baselines[\"baseline_avg_jacc\"], linestyle=':', color=colors[12], alpha=0.5, marker='x', label=\"baseline Jaccard\", visible=baseline)\n",
    "        plt.plot(cols, baselines[\"baseline_avg_rbo\"], linestyle=':', color=colors[9], alpha=0.5, marker='s', label=\"baseline RBO\", visible=baseline)\n",
    "        plt.fill_between(cols, data_f1.mean(axis=0)+data_f1.std(axis=0), data_f1.mean(axis=0)-data_f1.std(axis=0), color=colors[11], alpha=0.1)\n",
    "        plt.fill_between(cols, data_jacc.mean(axis=0)+data_jacc.std(axis=0), data_jacc.mean(axis=0)-data_jacc.std(axis=0), color=colors[12], alpha=0.2)\n",
    "        plt.fill_between(cols, data_rbo.mean(axis=0)+data_rbo.std(axis=0), data_rbo.mean(axis=0)-data_rbo.std(axis=0), color=colors[9], alpha=0.2)\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/all_metrics_stdev.pdf')\n",
    "\n",
    "    elif to_plot == \"tests\":\n",
    "        # F1 + all tests\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('F1-score', fontsize=15)\n",
    "        plt.title(f\"{question}: Number of reviews versus average F1 score\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, data_f1.mean(axis=0), color=colors[11], marker='o', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_f1\"], linestyle=':', color=colors[11], alpha=0.5, marker='o', label=\"baseline\", visible=baseline)\n",
    "        for i in range(1,len(tests)+1):\n",
    "            plt.plot(cols, list(data_f1.iloc[(len(categories)*i-len(categories)):len(categories)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=tests[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/F1_tests.pdf')\n",
    "\n",
    "        # Jaccard + all tests\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Jaccard similarity', fontsize=15)\n",
    "        plt.title(f\"{question}: Number of reviews versus average Jaccard similarities\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, data_jacc.mean(axis=0), color=colors[12], marker='x', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_jacc\"], linestyle=':', color=colors[12], alpha=0.5, marker='x', label=\"baseline\", visible=baseline)\n",
    "        for i in range(1,len(tests)+1):\n",
    "            plt.plot(cols, list(data_jacc.iloc[(len(categories)*i-len(categories)):len(categories)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=tests[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/Jacc_tests.pdf')\n",
    "\n",
    "        # RBO + all tests\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('RBO score', fontsize=15)\n",
    "        plt.title(f\"{question}: Number of reviews versus average RBO score\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_rbo\"], linestyle=':', color=colors[9], alpha=0.5, marker='s', label=\"baseline\", visible=baseline)\n",
    "        for i in range(1,len(tests)+1):\n",
    "            plt.plot(cols, list(data_rbo.iloc[(len(categories)*i-len(categories)):len(categories)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=tests[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/RBO_tests.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_r_metrics(data_f1, data_jacc, data_rbo, to_plot):\n",
    "    if to_plot == \"category\":\n",
    "        # individual categories with avg metrics\n",
    "        for i in range(1,len(categories)+1):\n",
    "            plt.figure(figsize=(15, 8))\n",
    "            plt.rc('font', size=12)\n",
    "            plt.xlabel('@r', fontsize=15)\n",
    "            plt.ylabel('Metric scores', fontsize=15)\n",
    "            plt.title(f\"{question}_{test}: Average metric performances @r for {categories[i-1]}\", fontsize=20)\n",
    "            plt.xticks(data_f1.columns+1)\n",
    "            plt.plot(data_f1.columns+1, list(data_f1.iloc[(len(cols)*i-len(cols)):len(cols)*i].mean(axis=0)), color=colors[11], marker='o', label=\"F1\")\n",
    "            plt.plot(data_jacc.columns+1, list(data_jacc.iloc[(len(cols)*i-len(cols)):len(cols)*i].mean(axis=0)), color=colors[12], marker='x', label=\"Jaccard\")\n",
    "            plt.plot(data_rbo.columns+1, list(data_rbo.iloc[(len(cols)*i-len(cols)):len(cols)*i].mean(axis=0)), color=colors[9], marker='s', label=\"RBO\")\n",
    "            l = baselines[f\"baseline_{categories[i-1]}_f1_r\"]\n",
    "            l = l+[np.nan]*(len(data_f1.columns)-len(l))\n",
    "            plt.plot(data_f1.columns+1, l[:len(data_f1.columns)], linestyle=':', color=colors[11], alpha=0.5, marker='o', label=\"baseline F1\", visible=baseline)\n",
    "            l = baselines[f\"baseline_{categories[i-1]}_jacc_r\"]\n",
    "            l = l+[np.nan]*(len(data_jacc.columns)-len(l))\n",
    "            plt.plot(data_jacc.columns+1, l[:len(data_jacc.columns)], linestyle=':', color=colors[12], alpha=0.5, marker='x', label=\"baseline Jaccard\", visible=baseline)\n",
    "            l = baselines[f\"baseline_{categories[i-1]}_rbo_r\"]\n",
    "            l = l+[np.nan]*(len(data_rbo.columns)-len(l))\n",
    "            plt.plot(data_rbo.columns+1, l[:len(data_rbo.columns)], linestyle=':', color=colors[9], alpha=0.5, marker='s', label=\"baseline RBO\", visible=baseline)\n",
    "            plt.legend(loc=2)\n",
    "            if save:\n",
    "                plt.savefig(f'Evaluation/{question}/{test}/individual_@r_{categories[i-1]}.pdf')\n",
    "\n",
    "    elif to_plot == \"all\":\n",
    "        # whole RQ1\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@r', fontsize=15)\n",
    "        plt.ylabel('Metric scores', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Average metric performances @r\", fontsize=20)\n",
    "        plt.xticks(data_f1.columns+1)\n",
    "        plt.plot(data_f1.columns+1, data_f1.mean(axis=0), color=colors[11], marker='o', label=\"F1\")\n",
    "        plt.plot(data_jacc.columns+1, data_jacc.mean(axis=0), color=colors[12], marker='x', label=\"Jaccard\")\n",
    "        plt.plot(data_rbo.columns+1, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"RBO\")\n",
    "        l = baselines[\"baseline_avg_f1_r\"]\n",
    "        l = l+[np.nan]*(len(data_f1.columns)-len(l))\n",
    "        plt.plot(data_f1.columns+1, l[:len(data_f1.columns)], linestyle=':', color=colors[11], alpha=0.5, marker='o', label=\"baseline F1\", visible=baseline)\n",
    "        l = baselines[\"baseline_avg_jacc_r\"]\n",
    "        l = l+[np.nan]*(len(data_jacc.columns)-len(l))\n",
    "        plt.plot(data_jacc.columns+1, l[:len(data_jacc.columns)], linestyle=':', color=colors[12], alpha=0.5, marker='x', label=\"baseline Jaccard\", visible=baseline)\n",
    "        l = baselines[\"baseline_avg_rbo_r\"]\n",
    "        l = l+[np.nan]*(len(data_rbo.columns)-len(l))\n",
    "        plt.plot(data_rbo.columns+1, l[:len(data_rbo.columns)], linestyle=':', color=colors[9], alpha=0.5, marker='s', label=\"baseline RBO\", visible=baseline)\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/@r_all_metrics.pdf')\n",
    "\n",
    "        # whole RQ1 with stdev\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@r', fontsize=15)\n",
    "        plt.ylabel('Metric scores', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Average metric performances @r with their standard deviations\", fontsize=20)\n",
    "        plt.xticks(data_f1.columns+1)\n",
    "        plt.plot(data_f1.columns+1, data_f1.mean(axis=0), color=colors[11], marker='o', label=\"F1\")\n",
    "        plt.plot(data_jacc.columns+1, data_jacc.mean(axis=0), color=colors[12], marker='x', label=\"Jaccard\")\n",
    "        plt.plot(data_rbo.columns+1, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"RBO\")\n",
    "        l = baselines[\"baseline_avg_f1_r\"]\n",
    "        l = l+[np.nan]*(len(data_f1.columns)-len(l))\n",
    "        plt.plot(data_f1.columns+1, l[:len(data_f1.columns)], linestyle=':', color=colors[11], alpha=0.5, marker='o', label=\"baseline F1\", visible=baseline)\n",
    "        l = baselines[\"baseline_avg_jacc_r\"]\n",
    "        l = l+[np.nan]*(len(data_jacc.columns)-len(l))\n",
    "        plt.plot(data_jacc.columns+1, l[:len(data_jacc.columns)], linestyle=':', color=colors[12], alpha=0.5, marker='x', label=\"baseline Jaccard\", visible=baseline)\n",
    "        l = baselines[\"baseline_avg_rbo_r\"]\n",
    "        l = l+[np.nan]*(len(data_rbo.columns)-len(l))\n",
    "        plt.plot(data_rbo.columns+1, l[:len(data_rbo.columns)], linestyle=':', color=colors[9], alpha=0.5, marker='s', label=\"baseline RBO\", visible=baseline)\n",
    "        plt.fill_between(data_f1.columns+1, data_f1.mean(axis=0)+data_f1.std(axis=0), data_f1.mean(axis=0)-data_f1.std(axis=0), color=colors[11], alpha=0.1)\n",
    "        plt.fill_between(data_jacc.columns+1, data_jacc.mean(axis=0)+data_jacc.std(axis=0), data_jacc.mean(axis=0)-data_jacc.std(axis=0), color=colors[12], alpha=0.2)\n",
    "        plt.fill_between(data_rbo.columns+1, data_rbo.mean(axis=0)+data_rbo.std(axis=0), data_rbo.mean(axis=0)-data_rbo.std(axis=0), color=colors[9], alpha=0.2)\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/@r_all_metrics_stdev.pdf')\n",
    "\n",
    "        # F1 + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@r', fontsize=15)\n",
    "        plt.ylabel('F1-scores', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: F1-scores @r\", fontsize=20)\n",
    "        plt.xticks(data_f1.columns+1)\n",
    "        plt.plot(data_f1.columns+1, data_f1.mean(axis=0), color=colors[11], marker='o', label=\"avg\")\n",
    "        l = baselines[\"baseline_avg_f1_r\"]\n",
    "        l = l+[np.nan]*(len(data_f1.columns)-len(l))\n",
    "        plt.plot(data_f1.columns+1, l[:len(data_f1.columns)], linestyle=':', color=colors[11], alpha=0.5, marker='o', label=\"baseline\", visible=baseline)\n",
    "        for i in range(1,len(categories)+1):\n",
    "            plt.plot(data_f1.columns+1, list(data_f1.iloc[(len(cols)*i-len(cols)):len(cols)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=categories[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/@r_F1_categories.pdf')\n",
    "\n",
    "        # Jaccard + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@r', fontsize=15)\n",
    "        plt.ylabel('Jaccard similarity', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Jaccard similarities @r\", fontsize=20)\n",
    "        plt.xticks(data_jacc.columns+1)\n",
    "        plt.plot(data_jacc.columns+1, data_jacc.mean(axis=0), color=colors[12], marker='x', label=\"avg\")\n",
    "        l = baselines[\"baseline_avg_jacc_r\"]\n",
    "        l = l+[np.nan]*(len(data_jacc.columns)-len(l))\n",
    "        plt.plot(data_jacc.columns+1, l[:len(data_jacc.columns)], linestyle=':', color=colors[12], alpha=0.5, marker='x', label=\"baseline\", visible=baseline)\n",
    "        for i in range(1,len(categories)+1):\n",
    "            plt.plot(data_jacc.columns+1, list(data_jacc.iloc[(len(cols)*i-len(cols)):len(cols)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=categories[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/@r_jacc_categories.pdf')\n",
    "\n",
    "        # rbo + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@r', fontsize=15)\n",
    "        plt.ylabel('RBO', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: RBO @r\", fontsize=20)\n",
    "        plt.xticks(data_rbo.columns+1)\n",
    "        plt.plot(data_rbo.columns+1, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"avg\")\n",
    "        l = baselines[\"baseline_avg_rbo_r\"]\n",
    "        l = l+[np.nan]*(len(data_rbo.columns)-len(l))\n",
    "        plt.plot(data_rbo.columns+1, l[:len(data_rbo.columns)], linestyle=':', color=colors[9], alpha=0.5, marker='s', label=\"baseline\", visible=baseline)\n",
    "        for i in range(1,len(categories)+1):\n",
    "            plt.plot(data_rbo.columns+1, list(data_rbo.iloc[(len(cols)*i-len(cols)):len(cols)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=categories[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/@r_rbo_categories.pdf')\n",
    "            \n",
    "    elif to_plot == \"tests\":\n",
    "        # F1 + all_tests\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@r', fontsize=15)\n",
    "        plt.ylabel('F1-scores', fontsize=15)\n",
    "        plt.title(f\"{question}: F1-scores @r\", fontsize=20)\n",
    "        plt.xticks(data_f1.columns+1)\n",
    "        plt.plot(data_f1.columns+1, data_f1.mean(axis=0), color=colors[11], marker='o', label=\"avg\")\n",
    "        l = baselines[\"baseline_avg_f1_r\"]\n",
    "        l = l+[np.nan]*(len(data_f1.columns)-len(l))\n",
    "        plt.plot(data_f1.columns+1, l[:len(data_f1.columns)], linestyle=':', color=colors[11], alpha=0.5, marker='o', label=\"baseline\", visible=baseline)\n",
    "        for i in range(len(data_f1)):\n",
    "            plt.plot(data_f1.columns+1, list(data_f1.loc[i,:]), linestyle='--', color=colors[i+3], label=tests[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/@r_F1_tests.pdf')\n",
    "            \n",
    "        # Jaccard + all tests\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@r', fontsize=15)\n",
    "        plt.ylabel('Jaccard similarity', fontsize=15)\n",
    "        plt.title(f\"{question}: Jaccard similarities @r\", fontsize=20)\n",
    "        plt.xticks(data_jacc.columns+1)\n",
    "        plt.plot(data_jacc.columns+1, data_jacc.mean(axis=0), color=colors[12], marker='x', label=\"avg\")\n",
    "        l = baselines[\"baseline_avg_jacc_r\"]\n",
    "        l = l+[np.nan]*(len(data_jacc.columns)-len(l))\n",
    "        plt.plot(data_jacc.columns+1, l[:len(data_jacc.columns)], linestyle=':', color=colors[12], alpha=0.5, marker='x', label=\"baseline\", visible=baseline)\n",
    "        for i in range(len(data_jacc)):\n",
    "            plt.plot(data_jacc.columns+1, list(data_jacc.loc[i,:]), linestyle='--', color=colors[i+3], label=tests[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/@r_Jacc_tests.pdf')\n",
    "\n",
    "        # rbo + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@r', fontsize=15)\n",
    "        plt.ylabel('RBO', fontsize=15)\n",
    "        plt.title(f\"{question}: RBO @r\", fontsize=20)\n",
    "        plt.xticks(data_rbo.columns+1)\n",
    "        plt.plot(data_rbo.columns+1, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"avg\")\n",
    "        l = baselines[\"baseline_avg_rbo_r\"]\n",
    "        l = l+[np.nan]*(len(data_rbo.columns)-len(l))\n",
    "        plt.plot(data_rbo.columns+1, l[:len(data_rbo.columns)], linestyle=':', color=colors[9], alpha=0.5, marker='s', label=\"baseline\", visible=baseline)\n",
    "        for i in range(len(data_rbo)):\n",
    "            plt.plot(data_rbo.columns+1, list(data_rbo.loc[i,:]), linestyle='--', color=colors[i+3], label=tests[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/@r_rbo_tests.pdf')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_p_metrics(data_rbo, to_plot):\n",
    "    if to_plot == \"category\":\n",
    "        # individual categories with avg metrics\n",
    "        for i in range(1,len(categories)+1):\n",
    "            plt.figure(figsize=(15, 8))\n",
    "            plt.rc('font', size=12)\n",
    "            plt.xlabel('@p', fontsize=15)\n",
    "            plt.ylabel('RBO similarity', fontsize=15)\n",
    "            plt.title(f\"{question}_{test}: Average RBO similarity @p for {categories[i-1]}\", fontsize=20)\n",
    "            plt.xticks((data_rbo.columns+1)/10)\n",
    "            plt.plot((data_rbo.columns+1)/10, list(data_rbo.iloc[(len(cols)*i-len(cols)):len(cols)*i].mean(axis=0)), color=colors[9], marker='s', label=\"RBO\")\n",
    "            plt.plot((data_rbo.columns+1)/10, baselines[f\"baseline_{categories[i-1]}_rbo_p\"], linestyle=':', color=colors[9], alpha=0.5, marker='s', label=\"baseline\", visible=baseline)\n",
    "            plt.legend(loc=2)\n",
    "            if save:\n",
    "                plt.savefig(f'Evaluation/{question}/{test}/individual_rbo@p_{categories[i-1]}.pdf')\n",
    "\n",
    "    elif to_plot == \"all\":\n",
    "        # whole RQ1\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@p', fontsize=15)\n",
    "        plt.ylabel('RBO similarity', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Average RBO similarity @p\", fontsize=20)\n",
    "        plt.xticks((data_rbo.columns+1)/10)\n",
    "        plt.plot((data_rbo.columns+1)/10, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"RBO\")\n",
    "        plt.plot((data_rbo.columns+1)/10, baselines[\"baseline_avg_rbo_p\"], linestyle=':', color=colors[9], alpha=0.5, marker='s', label=\"baseline\", visible=baseline)\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/rbo@p_all_metrics.pdf')\n",
    "\n",
    "        # whole RQ1 with stdev\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@p', fontsize=15)\n",
    "        plt.ylabel('RBO similarity', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Average RBO similarity @p with its standard deviation\", fontsize=20)\n",
    "        plt.xticks((data_rbo.columns+1)/10)\n",
    "        plt.plot((data_rbo.columns+1)/10, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"RBO\")\n",
    "        plt.plot((data_rbo.columns+1)/10, baselines[\"baseline_avg_rbo_p\"], linestyle=':', color=colors[9], alpha=0.5, marker='s', label=\"baseline\", visible=baseline)\n",
    "        plt.fill_between((data_rbo.columns+1)/10, data_rbo.mean(axis=0)+data_rbo.std(axis=0), data_rbo.mean(axis=0)-data_rbo.std(axis=0), color=colors[9], alpha=0.2)\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/rbo@p_all_metrics_stdev.pdf')\n",
    "\n",
    "        # rbo + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@p', fontsize=15)\n",
    "        plt.ylabel('RBO', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: RBO similarity @p\", fontsize=20)\n",
    "        plt.xticks((data_rbo.columns+1)/10)\n",
    "        plt.plot((data_rbo.columns+1)/10, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"avg\")\n",
    "        plt.plot((data_rbo.columns+1)/10, baselines[\"baseline_avg_rbo_p\"], linestyle=':', color=colors[9], alpha=0.5, marker='s', label=\"baseline\", visible=baseline)\n",
    "        for i in range(1,len(categories)+1):\n",
    "            plt.plot((data_rbo.columns+1)/10, list(data_rbo.iloc[(len(cols)*i-len(cols)):len(cols)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=categories[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/rbo@p_categories.pdf')\n",
    "            \n",
    "    elif to_plot == \"tests\":\n",
    "        \n",
    "        # rbo + tests\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@p', fontsize=15)\n",
    "        plt.ylabel('RBO', fontsize=15)\n",
    "        plt.title(f\"{question}: RBO similarity @p\", fontsize=20)\n",
    "        plt.xticks((data_rbo.columns+1)/10)\n",
    "        plt.plot((data_rbo.columns+1)/10, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"avg\")\n",
    "        plt.plot((data_rbo.columns+1)/10, baselines[\"baseline_avg_rbo_p\"], linestyle=':', color=colors[9], alpha=0.5, marker='s', label=\"baseline\", visible=baseline)\n",
    "        for i in range(len(data_rbo)):\n",
    "            plt.plot((data_rbo.columns+1)/10, list(data_rbo.loc[i,:]), linestyle='--', color=colors[i+3], label=tests[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/rbo@p_tests.pdf')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_specifics(removed, size, rel, to_plot):\n",
    "    \n",
    "    if to_plot == \"all\":\n",
    "        # relevance + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Relevance', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Average relevance of reviews in the final ranking\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, rel.mean(axis=0), color=colors[1], marker='o', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_rel\"], linestyle=':', color=colors[1], alpha=0.5, marker='o', label=\"baseline\", visible=baseline)\n",
    "        for i in range(len(rel)):\n",
    "            plt.plot(cols, list(rel.loc[i,:]), linestyle='--', color=colors[i+3], label=categories[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/relevance_categories.pdf')\n",
    "            \n",
    "        # relevance + stdev\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Relevance', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Average relevance of reviews in the final ranking with its standard deviation\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, rel.mean(axis=0), color=colors[1], marker='o', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_rel\"], linestyle=':', color=colors[1], alpha=0.5, marker='o', label=\"baseline\", visible=baseline)\n",
    "        plt.fill_between(cols, rel.mean(axis=0)+rel.std(axis=0), rel.mean(axis=0)-rel.std(axis=0), color=colors[8], alpha=0.3)\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/relevance_stdev.pdf')\n",
    "            \n",
    "        # removed + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Number of removed reviews from relevance model', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Average removal of reviews from the relevance model\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, removed.mean(axis=0), color=colors[2], marker='x', label=\"avg\")\n",
    "        for i in range(len(removed)):\n",
    "            plt.plot(cols, list(removed.loc[i,:]), linestyle='--', color=colors[i+3], label=categories[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/removed_categories.pdf')\n",
    "            \n",
    "        # size + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Size of the relevance model', fontsize=15)\n",
    "        plt.title(f\"{question}_{test}: Average size of the relevance model\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, size.mean(axis=0), color=colors[13], marker='h', label=\"avg\")\n",
    "        for i in range(len(size)):\n",
    "            plt.plot(cols, list(size.loc[i,:]), linestyle='--', color=colors[i+3], label=categories[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/size_categories.pdf')\n",
    "            \n",
    "        # removed + size\n",
    "        y1 = removed.mean(axis=0)\n",
    "        y2 = size.mean(axis=0)\n",
    "        fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        line1, = ax1.plot(cols, y1, color=colors[2], marker='x', label=\"removed\")\n",
    "        line2, = ax2.plot(cols, y2, color=colors[13], marker='h', label=\"size\")\n",
    "    \n",
    "        ax1.set_xlabel('Number of reviews', fontsize=15)\n",
    "        ax1.set_ylabel('Number of removed reviews from relevance model', color=colors[2], fontsize=15)\n",
    "        ax2.set_ylabel('Size of the relevance model', color=colors[13], fontsize=15)\n",
    "        ax1.set_xticks(cols)\n",
    "        ax2.set_xticks(cols)\n",
    "        ax1.legend(handles=[line1, line2], loc=2)\n",
    "        ax2.set_title(f\"{question}_{test}: Removed from & size of relevance model\", fontsize=20) #, {test}')\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/removed_size.pdf')\n",
    "            \n",
    "        # removed + size + stdev\n",
    "        y1 = removed.mean(axis=0)\n",
    "        y2 = size.mean(axis=0)\n",
    "        fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        line1, = ax1.plot(cols, y1, color=colors[2], marker='x', label=\"removed\")\n",
    "        line2, = ax2.plot(cols, y2, color=colors[13], marker='h', label=\"size\")\n",
    "    \n",
    "        ax1.fill_between(cols, y1+removed.std(axis=0), y1-removed.std(axis=0), color=colors[2], alpha=0.1)\n",
    "        ax2.fill_between(cols, y2+size.std(axis=0), y2-size.std(axis=0), color=colors[13], alpha=0.3)\n",
    "\n",
    "        ax1.set_xlabel('Number of reviews', fontsize=15)\n",
    "        ax1.set_ylabel('Number of removed reviews from relevance model', color=colors[2], fontsize=15)\n",
    "        ax2.set_ylabel('Size of the relevance model', color=colors[13], fontsize=15)\n",
    "        ax1.set_xticks(cols)\n",
    "        ax2.set_xticks(cols)\n",
    "        ax1.legend(handles=[line1, line2], loc=2)\n",
    "        ax2.set_title(f\"{question}_{test}: Removed from & size of relevance model with their standard deviations\", fontsize=20) #, {test}')\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/{test}/removed_size_stdev.pdf')\n",
    "    \n",
    "    elif to_plot == \"tests\":\n",
    "        # relevance + tests\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Relevance', fontsize=15)\n",
    "        plt.title(f\"{question}: Average relevance of reviews in the final ranking\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, rel.mean(axis=0), color=colors[1], marker='o', label=\"avg\")\n",
    "        plt.plot(cols, baselines[\"baseline_avg_rel\"], linestyle=':', color=colors[1], alpha=0.5, marker='o', label=\"baseline\", visible=baseline)\n",
    "        for i in range(1,len(tests)+1):\n",
    "            plt.plot(cols, list(rel.iloc[(len(categories)*i-len(categories)):len(categories)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=tests[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/relevance_tests.pdf')\n",
    "\n",
    "        # removed + tests\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Number of removed reviews from relevance model', fontsize=15)\n",
    "        plt.title(f\"{question}: Average removal of reviews from the relevance model\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, removed.mean(axis=0), color=colors[2], marker='x', label=\"avg\")\n",
    "        for i in range(1,len(tests)+1):\n",
    "            plt.plot(cols, list(removed.iloc[(len(categories)*i-len(categories)):len(categories)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=tests[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/removed_tests.pdf')\n",
    "            \n",
    "        # size + tests\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Size of the relevance model', fontsize=15)\n",
    "        plt.title(f\"{question}: Average size of the relevance model\", fontsize=20)\n",
    "        plt.xticks(cols)\n",
    "        plt.plot(cols, size.mean(axis=0), color=colors[13], marker='h', label=\"avg\")\n",
    "        for i in range(1,len(tests)+1):\n",
    "            plt.plot(cols, list(size.iloc[(len(categories)*i-len(categories)):len(categories)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=tests[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/size_tests.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "save = False # for saving plots\n",
    "baseline = True\n",
    "\n",
    "questions = {\"RQ3b\":[\"Office_Products\",\"Movies_and_TV\",\"Electronics\",\"Home_and_Kitchen\",\"Sports_and_Outdoors\"]}\n",
    "tests = [\"1days\", \"2days\", \"7days\", \"30days\", \"90days\", \"183days\", \"365days\", \"730days\"]\n",
    "\n",
    "for question, categories in questions.items():\n",
    "\n",
    "    cols = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160]\n",
    "\n",
    "    clust_RQ = pd.DataFrame(columns=cols)\n",
    "    run_RQ = pd.DataFrame(columns=cols)\n",
    "    len_ranking_RQ = pd.DataFrame(columns=cols)\n",
    "    perc_ranking_RQ = pd.DataFrame(columns=cols)\n",
    "    perc_step3_RQ = pd.DataFrame(columns=cols)\n",
    "    f1_r_RQ = [] \n",
    "    f1_nr_rev_RQ = pd.DataFrame(columns=cols)\n",
    "    jacc_r_RQ = []\n",
    "    jacc_nr_rev_RQ = pd.DataFrame(columns=cols)\n",
    "    rbo_r_RQ = []\n",
    "    rbo_p_RQ = []\n",
    "    rbo_nr_rev_RQ = pd.DataFrame(columns=cols)\n",
    "    removed_RQ = pd.DataFrame(columns=cols)\n",
    "    size_RQ = pd.DataFrame(columns=cols)\n",
    "    rel_RQ = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    for test in tests:\n",
    "        clust_test = pd.DataFrame(columns=cols)\n",
    "        run_test = pd.DataFrame(columns=cols)\n",
    "        len_ranking_test = pd.DataFrame(columns=cols)\n",
    "        perc_ranking_test = pd.DataFrame(columns=cols)\n",
    "        perc_step3_test = pd.DataFrame(columns=cols)\n",
    "        f1_r_test = []\n",
    "        f1_nr_rev_test = pd.DataFrame(columns=cols)\n",
    "        jacc_r_test = []\n",
    "        jacc_nr_rev_test = pd.DataFrame(columns=cols)\n",
    "        rbo_r_test = []\n",
    "        rbo_p_test = []\n",
    "        rbo_nr_rev_test = pd.DataFrame(columns=cols)\n",
    "        removed_test = pd.DataFrame(columns=cols)\n",
    "        size_test = pd.DataFrame(columns=cols)\n",
    "        rel_test = pd.DataFrame(columns=cols)\n",
    "\n",
    "        for category in categories:\n",
    "            with open(f'Evaluation/{question}/{test}/evaluations.txt', 'a') as f:\n",
    "                clust_cat = []\n",
    "                run_cat = []\n",
    "                len_ranking_cat = []\n",
    "                perc_ranking_cat = []\n",
    "                perc_step3_cat = []\n",
    "                f1_nr_rev_cat = []\n",
    "                jacc_nr_rev_cat = []\n",
    "                rbo_nr_rev_cat = []\n",
    "                removed_cat = []\n",
    "                size_cat = []\n",
    "                rel_cat = []\n",
    "\n",
    "                nr_revs = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160]\n",
    "\n",
    "                for nr_rev in nr_revs:\n",
    "                    f1_r_nr_rev = []\n",
    "                    jacc_r_nr_rev = []\n",
    "                    rbo_r_nr_rev = []\n",
    "                    rbo_p_nr_rev = []\n",
    "\n",
    "                    path = f'Results/{question}/{test}/{category}/{nr_rev}'\n",
    "\n",
    "                    start_evaluation()\n",
    "\n",
    "                    print(f'\\nClustered:\\n{clust_cat}', file=f)\n",
    "                    print(f'\\nRun time:\\n{run_cat}\\n\\n', file=f)\n",
    "                    print(f'\\nLength of final ranking:\\n{len_ranking_cat}\\n', file=f)\n",
    "                    print(f'\\nPercentage of final ranking:\\n{perc_ranking_cat}\\n', file=f)\n",
    "                    print(f'\\nPercentage of successful step3s:\\n{perc_step3_cat}\\n', file=f)\n",
    "                    print(f'\\nF1-scores:\\n{f1_nr_rev_cat}\\n', file=f)\n",
    "                    print(f'\\nJaccard distances:\\n{jacc_nr_rev_cat}\\n', file=f)\n",
    "                    print(f'\\nRBO distances:\\n{rbo_nr_rev_cat}\\n', file=f)\n",
    "                    print(f'\\nAverage relevance:\\n{rel_cat}\\n', file=f)\n",
    "                    print(f'\\n:Removed from relevance mode\\n{removed_cat}\\n', file=f)\n",
    "                    print(f'\\nSize of relevance model:\\n{size_cat}\\n', file=f)\n",
    "\n",
    "                    f1_r_test.append(f1_r_nr_rev)\n",
    "                    jacc_r_test.append(jacc_r_nr_rev)\n",
    "                    rbo_r_test.append(rbo_r_nr_rev)\n",
    "                    rbo_p_test.append(rbo_p_nr_rev)\n",
    "\n",
    "                clust_test.loc[len(clust_test)] = clust_cat\n",
    "                run_test.loc[len(run_test)] = run_cat\n",
    "                len_ranking_test.loc[len(len_ranking_test)] = len_ranking_cat\n",
    "                perc_ranking_test.loc[len(perc_ranking_test)] = perc_ranking_cat\n",
    "                perc_step3_test.loc[len(perc_step3_test)]  = perc_step3_cat\n",
    "                f1_nr_rev_test.loc[len(f1_nr_rev_test)] = f1_nr_rev_cat\n",
    "                jacc_nr_rev_test.loc[len(jacc_nr_rev_test)] = jacc_nr_rev_cat\n",
    "                rbo_nr_rev_test.loc[len(rbo_nr_rev_test)] = rbo_nr_rev_cat\n",
    "                removed_test.loc[len(removed_test)] = removed_cat\n",
    "                size_test.loc[len(size_test)] = size_cat\n",
    "                rel_test.loc[len(rel_test)] = rel_cat\n",
    "\n",
    "                plot_clust_run(pd.DataFrame([clust_cat]), pd.DataFrame([run_cat]), \"category\")\n",
    "                plot_metrics(pd.DataFrame([f1_nr_rev_cat]), pd.DataFrame([jacc_nr_rev_cat]), pd.DataFrame([rbo_nr_rev_cat]), \"category\")\n",
    "\n",
    "        clust_RQ = clust_RQ.append(clust_test)\n",
    "        run_RQ = run_RQ.append(run_test)\n",
    "        len_ranking_RQ = len_ranking_RQ.append(len_ranking_test)\n",
    "        perc_ranking_RQ = perc_ranking_RQ.append(perc_ranking_test)\n",
    "        perc_step3_RQ = perc_step3_RQ.append(perc_step3_test)\n",
    "        f1_nr_rev_RQ = f1_nr_rev_RQ.append(f1_nr_rev_test)\n",
    "        jacc_nr_rev_RQ = jacc_nr_rev_RQ.append(jacc_nr_rev_test)\n",
    "        rbo_nr_rev_RQ = rbo_nr_rev_RQ.append(rbo_nr_rev_test) \n",
    "        f1_r_RQ.append(pd.DataFrame(f1_r_test).mean(axis=0))\n",
    "        jacc_r_RQ.append(pd.DataFrame(jacc_r_test).mean(axis=0))\n",
    "        rbo_r_RQ.append(pd.DataFrame(rbo_r_test).mean(axis=0))\n",
    "        rbo_p_RQ.append(pd.DataFrame(rbo_p_test).mean(axis=0))\n",
    "        removed_RQ = removed_RQ.append(removed_test)\n",
    "        size_RQ = size_RQ.append(size_test)\n",
    "        rel_RQ = rel_RQ.append(rel_test)\n",
    "            \n",
    "        plot_clust_run(clust_test, run_test, \"all\")\n",
    "        plot_ranking(len_ranking_test, perc_ranking_test, perc_step3_test, \"\")\n",
    "        plot_metrics(f1_nr_rev_test, jacc_nr_rev_test, rbo_nr_rev_test, \"all\")\n",
    "        plot_r_metrics(pd.DataFrame(f1_r_test), pd.DataFrame(jacc_r_test), pd.DataFrame(rbo_r_test), \"category\")\n",
    "        plot_r_metrics(pd.DataFrame(f1_r_test), pd.DataFrame(jacc_r_test), pd.DataFrame(rbo_r_test), \"all\")\n",
    "        plot_p_metrics(pd.DataFrame(rbo_p_test), \"category\")\n",
    "        plot_p_metrics(pd.DataFrame(rbo_p_test), \"all\")\n",
    "        plot_test_specifics(removed_test, size_test, rel_test, \"all\")\n",
    "        \n",
    "    plot_clust_run(clust_RQ, run_RQ, \"tests\")\n",
    "    plot_ranking(len_ranking_RQ, perc_ranking_RQ, perc_step3_RQ, \"tests\")\n",
    "    plot_metrics(f1_nr_rev_RQ, jacc_nr_rev_RQ, rbo_nr_rev_RQ, \"tests\")\n",
    "    plot_r_metrics(pd.DataFrame(f1_r_RQ), pd.DataFrame(jacc_r_RQ), pd.DataFrame(rbo_r_RQ), \"tests\")\n",
    "    plot_p_metrics(pd.DataFrame(rbo_p_RQ), \"tests\")\n",
    "    plot_test_specifics(removed_RQ, size_RQ, rel_RQ, \"tests\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rbo\n",
    "\n",
    "\n",
    "colors = {1 : '#8f2011', 2: '#2B4C85', 3: '#91CDB7', 4: '#E7D995', 5: '#D68A91', \n",
    "          6: '#E89762', 7: '#50AFC7', 8: '#CDB29E', 9: '#C7CBCC', 10: '#A6C5D6',\n",
    "          11: '#6B7B8E', 12: '#957DAD'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_evaluation():\n",
    "    \n",
    "    if (category == \"Home_and_Kitchen\" and nr_rev == 4130) or (category == \"Video_Games\" and nr_rev == 2593):\n",
    "        print(f'-----No data available for {category} {nr_rev}-----',file=f)\n",
    "        clust_cat.append(np.nan)\n",
    "        run_cat.append(np.nan)\n",
    "        len_ranking_cat.append(np.nan)\n",
    "        perc_ranking_cat.append(np.nan)\n",
    "        perc_step3_cat.append(np.nan)\n",
    "        for r in range(1,49):\n",
    "            f1_r_cat.append(np.nan)\n",
    "            jacc_r_cat.append(np.nan)\n",
    "            rbo_r_cat.append(np.nan)\n",
    "        \n",
    "        rbo_nr_rev_cat.append(np.nan)\n",
    "        jacc_nr_rev_cat.append(np.nan)\n",
    "        f1_nr_rev_cat.append(np.nan)\n",
    "              \n",
    "        for p in range(1,11):\n",
    "            rbo_p_cat.append(np.nan)\n",
    "            \n",
    "    else:\n",
    "        results = pd.read_csv(f'{path}/results.txt', sep='\\n', header=None)\n",
    "\n",
    "        step3_len = evaluate_clustering_and_time(results)\n",
    "\n",
    "        evaluate_ranking(step3_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clustering_and_time(results):\n",
    "    cat = [cat[2] for cat in results[results[0].str.contains(\"Category:\")][0].str.split(\" \")][0]\n",
    "    asin = [asin[2] for asin in results[results[0].str.contains(\"Found asin_id:\")][0].str.split(\" \")][0]\n",
    "    size = [size[4] for size in results[results[0].str.contains(\"Chosen product:\")][0].str.split(\" \")][0]\n",
    "\n",
    "    time = [time[1] for time in results[results[0].str.contains(\"seconds\")][0].str.split(\" \")][0]\n",
    "    clustered = [clus[-1] for clus in results[results[0].str.contains(\"mean:\")][0].str.split(\" \")][0]\n",
    "\n",
    "    clust_cat.append(100-float(clustered))\n",
    "    run_cat.append(float(time))\n",
    "    \n",
    "    step3_len = len(results[results[0].str.contains(\"\\t\\tstep 3\")])\n",
    "\n",
    "    print(f'-----{cat} {asin} {size}-----', file=f)\n",
    "    \n",
    "    return step3_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ranking(step3_len):\n",
    "    all_files = sorted(glob.glob(f'{path}/*.csv'))\n",
    "\n",
    "    ranking = pd.read_csv(all_files[0], sep=';').drop_duplicates('review')\n",
    "    ground_truth = pd.read_csv(all_files[1], sep=';', index_col=0)\n",
    "\n",
    "    ranking['Model ranking'] = ranking['Model ranking'] + 1\n",
    "\n",
    "    print(f\"\\nLength of final ranking:\\n{len(ranking)}\\n\", file=f)\n",
    "\n",
    "    len_ranking_cat.append(len(ranking))\n",
    "    perc_ranking_cat.append(100*len(ranking)/nr_rev)\n",
    "    if step3_len > 0:\n",
    "        perc_step3_cat.append(100*len(ranking)/step3_len)\n",
    "    else:\n",
    "        perc_step3_cat.append(0)\n",
    "\n",
    "    f1_score(ranking, ground_truth)\n",
    "    \n",
    "    jaccard_similarity(ranking)\n",
    "    \n",
    "    rbo_score(ranking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(ranking, ground_truth):\n",
    "    \n",
    "    F1_score = np.nan\n",
    "    \n",
    "    for r in range(1,len(ranking)+1):\n",
    "        TP = 0\n",
    "        TN = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "\n",
    "        for elem in ranking['ranking'][:r]:\n",
    "            if elem in range(1,len(ranking[:r])+1):\n",
    "                TP +=1\n",
    "            else:\n",
    "                FP +=1\n",
    "\n",
    "        for elem in ground_truth[~ground_truth.ranking.isin(list(ranking['ranking'][:r]))]['ranking']:\n",
    "            if elem in range(1,len(ranking[:r])+1):\n",
    "                FN +=1\n",
    "            else:\n",
    "                TN +=1\n",
    "\n",
    "        print(f\"For r={r}\\n\\tTP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\", file=f)\n",
    "\n",
    "        accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "\n",
    "        if precision+recall > 0:\n",
    "            F1_score = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "        print(f\"\\tacc: {accuracy}, pre: {precision}, rec: {recall}, F1: {F1_score}\\n\", file=f)\n",
    "        f1_r_cat.append(F1_score)\n",
    "    \n",
    "        \n",
    "    f1_nr_rev_cat.append(F1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(ranking):\n",
    "    \n",
    "    similarity = 0\n",
    "    \n",
    "    for r in range(1,len(ranking)+1):\n",
    "        A = set(ranking['ranking'][:r])\n",
    "        B = set(ranking['Model ranking'][:r])\n",
    "\n",
    "        #Find intersection of two sets\n",
    "        nominator = A.intersection(B)\n",
    "\n",
    "        #Find union of two sets\n",
    "        denominator = A.union(B)\n",
    "\n",
    "        #Take the ratio of sizes\n",
    "        if len(denominator) > 0:\n",
    "            similarity = len(nominator)/len(denominator)\n",
    "\n",
    "        jacc_r_cat.append(similarity)\n",
    "        \n",
    "    jacc_nr_rev_cat.append(similarity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbo_score(ranking):\n",
    "    \n",
    "    # rbo with fluctuating p\n",
    "    for p in range(1,11):\n",
    "        rbo_p_cat.append(rbo.RankingSimilarity(list(ranking['Model ranking']), list(ranking['ranking'])).rbo(p=p/10))\n",
    "    \n",
    "    rbo_score = np.nan\n",
    "    \n",
    "    # rbo with fluctuating r, p=1 (no weight)\n",
    "    for r in range(1,len(ranking)+1):\n",
    "        rbo_score = rbo.RankingSimilarity(list(ranking['Model ranking']), list(ranking['ranking'])).rbo()\n",
    "        rbo_r_cat.append(rbo_score)\n",
    "        \n",
    "    rbo_nr_rev_cat.append(rbo_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clust_run(clust, run, to_plot):\n",
    "    \n",
    "    if to_plot == \"category\":\n",
    "    \n",
    "        # individual categories\n",
    "        y1 = clust.mean(axis=0)\n",
    "        y2 = run.mean(axis=0)\n",
    "        fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        line1, = ax1.plot(cols, y1, color=colors[1], marker='o', label=\"%cluster\")\n",
    "        line2, = ax2.plot(cols, y2, color=colors[2], marker='x', label=\"run time\")\n",
    "\n",
    "        ax1.set_xlabel('Number of reviews', fontsize=15)\n",
    "        ax1.set_ylabel('% of clustered reviews', color=colors[1], fontsize=15)\n",
    "        ax2.set_ylabel('Runtime in seconds', color=colors[2], fontsize=15)\n",
    "        ax1.set_xticks(cols)\n",
    "        ax2.set_xticks(cols)\n",
    "        ax1.legend(handles=[line1, line2], loc=2)\n",
    "        ax2.set_title(f\"{question}: Cluster percentage & run time for {category}\", fontsize=20)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/individual_clust_run_{category}.pdf')\n",
    "    \n",
    "    elif to_plot == \"all\":\n",
    "        # clust + run average\n",
    "        y1 = clust.mean(axis=0)\n",
    "        y2 = run.mean(axis=0)\n",
    "        fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        line1, = ax1.plot(cols, y1, color=colors[1], marker='o', label=\"%cluster\")\n",
    "        line2, = ax2.plot(cols, y2, color=colors[2], marker='x', label=\"run time\")\n",
    "\n",
    "        ax1.set_xlabel('Number of reviews', fontsize=15)\n",
    "        ax1.set_ylabel('% of clustered reviews', color=colors[1], fontsize=15)\n",
    "        ax2.set_ylabel('Runtime in seconds', color=colors[2], fontsize=15)\n",
    "        ax1.set_xticks(cols)\n",
    "        ax2.set_xticks(cols)\n",
    "        ax1.legend(handles=[line1, line2], loc=2)\n",
    "        ax2.set_title(f\"{question}: Average cluster percentage & run time\", fontsize=20)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/clust_run_all.pdf')\n",
    "        \n",
    "        # clust + run stdev\n",
    "        y1 = clust.mean(axis=0)\n",
    "        y2 = run.mean(axis=0)\n",
    "        fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        line1, = ax1.plot(cols, y1, color=colors[1], marker='o', label=\"%cluster\")\n",
    "        line2, = ax2.plot(cols, y2, color=colors[2], marker='x', label=\"run time\")\n",
    "        \n",
    "        ax1.fill_between(cols, y1+clust.std(axis=0), y1-clust.std(axis=0), color=colors[8], alpha=0.3)\n",
    "        ax2.fill_between(cols, y2+run.std(axis=0), y2-run.std(axis=0), color=colors[3], alpha=0.3)\n",
    "\n",
    "        ax1.set_xlabel('Number of reviews', fontsize=15)\n",
    "        ax1.set_ylabel('% of clustered reviews', color=colors[1], fontsize=15)\n",
    "        ax2.set_ylabel('Runtime in seconds', color=colors[2], fontsize=15)\n",
    "        ax1.set_xticks(cols)\n",
    "        ax2.set_xticks(cols)\n",
    "        ax1.legend(handles=[line1, line2], loc=2)\n",
    "        ax2.set_title(f\"{question}: Average cluster percentage & run time with their standard deviations\", fontsize=20) #, {test}')\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/clust_run_all_stdev.pdf')\n",
    "\n",
    "        # clust + category lines\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('% of clustered reviews', fontsize=15)\n",
    "        plt.title(f\"{question}: Cluster percentages\", fontsize=20)\n",
    "        plt.xticks(range(len(cols)), labels=cols)\n",
    "        plt.plot(cols, clust.mean(axis=0), color=colors[1], marker='o', label=\"avg\")\n",
    "        for i in range(len(clust)):\n",
    "            plt.plot(cols, list(clust.loc[i,:]), linestyle='--', color=colors[i+2], label=categories[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/clust_categories_all.pdf')\n",
    "\n",
    "        # run + category lines\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Runtime in seconds', fontsize=15)\n",
    "        plt.title(f\"{question}: Runtimes\", fontsize=20)\n",
    "        plt.xticks(range(len(cols)), labels=cols)\n",
    "        plt.plot(cols, run.mean(axis=0), color=colors[2], marker='x', label=\"avg\")\n",
    "        for i in range(len(run)):\n",
    "            plt.plot(cols, list(run.loc[i,:]), linestyle='--', color=colors[i+2], label=categories[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/run_categories_all.pdf')\n",
    "        \n",
    "        # clust + stdev\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('% of clustered reviews', fontsize=15)\n",
    "        plt.title(f\"{question}: Cluster percentage with its standard deviation\", fontsize=20)\n",
    "        plt.xticks(range(len(cols)), labels=cols)\n",
    "        plt.plot(cols, clust.mean(axis=0), color=colors[1], marker='o', label=\"avg\")\n",
    "        plt.fill_between(cols, clust.mean(axis=0)+clust.std(axis=0), clust.mean(axis=0)-clust.std(axis=0), color=colors[8], alpha=0.3)\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/clust_stdev_all.pdf')\n",
    "\n",
    "        # run + stdev\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Runtime in seconds', fontsize=15)\n",
    "        plt.title(f\"{question}: Runtime with its standard deviation\", fontsize=20)\n",
    "        plt.xticks(range(len(cols)), labels=cols)\n",
    "        plt.plot(cols, run.mean(axis=0), color=colors[2], marker='x', label=\"avg\")\n",
    "        plt.fill_between(cols, run.mean(axis=0)+run.std(axis=0), run.mean(axis=0)-run.std(axis=0), color=colors[3], alpha=0.3)\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/run_stdev_all.pdf')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ranking(data_len, data_perc, data_step3):\n",
    "    \n",
    "    # len + categories\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.rc('font', size=12)\n",
    "    plt.xlabel('Number of reviews', fontsize=15)\n",
    "    plt.ylabel('Number of reviews in final ranking', fontsize=15)\n",
    "    plt.title(f\"{question}: Number of reviews\", fontsize=20)\n",
    "    plt.xticks(range(len(cols)), labels=cols)\n",
    "    plt.plot(cols, data_len.mean(axis=0), color=colors[1], marker='o', label=\"avg\")\n",
    "    for i in range(len(data_len)):\n",
    "        plt.plot(cols, list(data_len.loc[i,:]), linestyle='--', color=colors[i+3], label=categories[i])\n",
    "    plt.legend(loc=2)\n",
    "    if save:\n",
    "        plt.savefig(f'Evaluation/{question}/len_categories.pdf')\n",
    "\n",
    "    # perc + categories\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.rc('font', size=12)\n",
    "    plt.xlabel('Number of reviews', fontsize=15)\n",
    "    plt.ylabel('Percentage of reviews in final ranking', fontsize=15)\n",
    "    plt.title(f\"{question}: Percentage of reviews\", fontsize=20)\n",
    "    plt.xticks(range(len(cols)), labels=cols)\n",
    "    plt.plot(cols, data_perc.mean(axis=0), color=colors[2], marker='x', label=\"avg\")\n",
    "    for i in range(len(data_perc)):\n",
    "        plt.plot(cols, list(data_perc.loc[i,:]), linestyle='--', color=colors[i+3], label=categories[i])\n",
    "    plt.legend(loc=2)\n",
    "    if save:\n",
    "        plt.savefig(f'Evaluation/{question}/perc_categories.pdf')\n",
    "\n",
    "    # len + perc + stdev\n",
    "    y1 = data_len.mean(axis=0)\n",
    "    y2 = data_perc.mean(axis=0)\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    line1, = ax1.plot(cols, y1, color=colors[1], marker='o', label=\"size\")\n",
    "    line2, = ax2.plot(cols, y2, color=colors[2], marker='x', label=\"%\")\n",
    "    \n",
    "    ax1.fill_between(cols, y1+data_len.std(axis=0), y1-data_len.std(axis=0), color=colors[8], alpha=0.3)\n",
    "    ax2.fill_between(cols, y2+data_perc.std(axis=0), y2-data_perc.std(axis=0), color=colors[3], alpha=0.3)\n",
    "\n",
    "    ax1.set_xlabel('Number of reviews', fontsize=15)\n",
    "    ax1.set_ylabel('Number of reviews in final ranking', color=colors[1], fontsize=15)\n",
    "    ax2.set_ylabel('Percentage of reviews in final ranking', color=colors[2], fontsize=15)\n",
    "    ax1.set_xticks(cols)\n",
    "    ax2.set_xticks(cols)\n",
    "    ax1.legend(handles=[line1, line2], loc=2)\n",
    "    ax2.set_title(f\"{question}: Number & percentage of reviews with their standard deviations\", fontsize=20) #, {test}')\n",
    "    if save:\n",
    "        plt.savefig(f'Evaluation/{question}/len_perc_stdev.pdf')\n",
    "\n",
    "    # step3 + categories\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.rc('font', size=12)\n",
    "    plt.xlabel('Number of reviews', fontsize=15)\n",
    "    plt.ylabel('Percentage of successful step 3s', fontsize=15)\n",
    "    plt.title(f\"{question}: Percentage of successful step 3s\", fontsize=20)\n",
    "    plt.xticks(range(len(cols)), labels=cols)\n",
    "    plt.plot(cols, data_step3.mean(axis=0), color=colors[1], marker='o', label=\"avg\")\n",
    "    for i in range(len(data_step3)):\n",
    "        plt.plot(cols, list(data_step3.loc[i,:]), linestyle='--', color=colors[i+3], label=categories[i])\n",
    "    plt.legend(loc=2)\n",
    "    if save:\n",
    "        plt.savefig(f'Evaluation/{question}/step3_categories.pdf')\n",
    "\n",
    "    # step3 + stdev\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.rc('font', size=12)\n",
    "    plt.xlabel('Number of reviews', fontsize=15)\n",
    "    plt.ylabel('Percentage of successful step 3s', fontsize=15)\n",
    "    plt.title(f\"{question}: Percentage of successful step 3s with its standard deviation\", fontsize=20)\n",
    "    plt.xticks(range(len(cols)), labels=cols)\n",
    "    plt.plot(cols, data_step3.mean(axis=0), color=colors[1], marker='o', label=\"avg\")\n",
    "    plt.fill_between(cols, data_step3.mean(axis=0)+data_step3.std(axis=0), data_step3.mean(axis=0)-data_step3.std(axis=0), color=colors[8], alpha=0.3)\n",
    "    if save:\n",
    "        plt.savefig(f'Evaluation/{question}/step3_stdev.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(data_f1, data_jacc, data_rbo, to_plot):\n",
    "    \n",
    "    if to_plot == \"category\":\n",
    "        # individual categories with all metrics\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Metric scores', fontsize=15)\n",
    "        plt.title(f\"{question}: Number of reviews with their performances for {category}\", fontsize=20)\n",
    "        plt.xticks(range(len(cols)), labels=cols)\n",
    "        plt.plot(cols, data_f1.mean(axis=0), color=colors[11], marker='o', label=\"F1\")\n",
    "        plt.plot(cols, data_jacc.mean(axis=0), color=colors[12], marker='x', label=\"Jaccard\")\n",
    "        plt.plot(cols, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"RBO\")\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/individual_metrics_{category}.pdf')\n",
    "    \n",
    "    elif to_plot == \"all\":\n",
    "        # F1 + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('F1-score', fontsize=15)\n",
    "        plt.title(f\"{question}: Number of reviews versus average F1 score\", fontsize=20)\n",
    "        plt.xticks(range(len(cols)), labels=cols)\n",
    "        plt.plot(cols, data_f1.mean(axis=0), color=colors[11], marker='o', label=\"avg\")\n",
    "        for i in range(len(data_f1)):\n",
    "            plt.plot(cols, list(data_f1.loc[i,:]), linestyle='--', color=colors[i+3], label=categories[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/F1_categories.pdf')\n",
    "\n",
    "        # Jaccard + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Jaccard similarity', fontsize=15)\n",
    "        plt.title(f\"{question}: Number of reviews versus average Jaccard similarities\", fontsize=20)\n",
    "        plt.xticks(range(len(cols)), labels=cols)\n",
    "        plt.plot(cols, data_jacc.mean(axis=0), color=colors[12], marker='x', label=\"avg\")\n",
    "        for i in range(len(data_jacc)):\n",
    "            plt.plot(cols, list(data_jacc.loc[i,:]), linestyle='--', color=colors[i+3], label=categories[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/Jacc_categories.pdf')\n",
    "\n",
    "        # RBO + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('RBO score', fontsize=15)\n",
    "        plt.title(f\"{question}: Number of reviews versus average RBO score\", fontsize=20)\n",
    "        plt.xticks(range(len(cols)), labels=cols)\n",
    "        plt.plot(cols, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"avg\")\n",
    "        for i in range(len(data_rbo)):\n",
    "            plt.plot(cols, list(data_rbo.loc[i,:]), linestyle='--', color=colors[i+3], label=categories[i])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/RBO_categories.pdf')\n",
    "\n",
    "        # all metrics\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Metric scores', fontsize=15)\n",
    "        plt.title(f\"{question}: Number of reviews with their performances\", fontsize=20)\n",
    "        plt.xticks(range(len(cols)), labels=cols)\n",
    "        plt.plot(cols, data_f1.mean(axis=0), color=colors[11], marker='o', label=\"F1\")\n",
    "        plt.plot(cols, data_jacc.mean(axis=0), color=colors[12], marker='x', label=\"Jaccard\")\n",
    "        plt.plot(cols, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"RBO\")\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/all_metrics.pdf')\n",
    "\n",
    "        # all metrics + stdev\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('Number of reviews', fontsize=15)\n",
    "        plt.ylabel('Metric scores', fontsize=15)\n",
    "        plt.title(f\"{question}: Number of reviews with their performances with their standard deviations\", fontsize=20)\n",
    "        plt.xticks(range(len(cols)), labels=cols)\n",
    "        plt.plot(cols, data_f1.mean(axis=0), color=colors[11], marker='o', label=\"F1\")\n",
    "        plt.plot(cols, data_jacc.mean(axis=0), color=colors[12], marker='x', label=\"Jaccard\")\n",
    "        plt.plot(cols, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"RBO\")\n",
    "        plt.fill_between(cols, data_f1.mean(axis=0)+data_f1.std(axis=0), data_f1.mean(axis=0)-data_f1.std(axis=0), color=colors[11], alpha=0.1)\n",
    "        plt.fill_between(cols, data_jacc.mean(axis=0)+data_jacc.std(axis=0), data_jacc.mean(axis=0)-data_jacc.std(axis=0), color=colors[12], alpha=0.2)\n",
    "        plt.fill_between(cols, data_rbo.mean(axis=0)+data_rbo.std(axis=0), data_rbo.mean(axis=0)-data_rbo.std(axis=0), color=colors[9], alpha=0.2)\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/all_metrics_stdev.pdf')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_r_metrics(data_f1, data_jacc, data_rbo, to_plot):\n",
    "    if to_plot == \"category\":\n",
    "        # individual categories with avg metrics\n",
    "        for i in range(1,len(categories)+1):\n",
    "            plt.figure(figsize=(15, 8))\n",
    "            plt.rc('font', size=12)\n",
    "            plt.xlabel('@r', fontsize=15)\n",
    "            plt.ylabel('Metric scores', fontsize=15)\n",
    "            plt.title(f\"{question}: Average metric performances @r for {categories[i-1]}\", fontsize=20)\n",
    "            plt.xticks(data_f1.columns+1)\n",
    "            plt.plot(data_f1.columns+1, list(data_f1.iloc[(len(cols)*i-len(cols)):len(cols)*i].mean(axis=0)), color=colors[11], marker='o', label=\"F1\")\n",
    "            plt.plot(data_jacc.columns+1, list(data_jacc.iloc[(len(cols)*i-len(cols)):len(cols)*i].mean(axis=0)), color=colors[12], marker='x', label=\"Jaccard\")\n",
    "            plt.plot(data_rbo.columns+1, list(data_rbo.iloc[(len(cols)*i-len(cols)):len(cols)*i].mean(axis=0)), color=colors[9], marker='s', label=\"RBO\")\n",
    "            plt.legend(loc=2)\n",
    "            if save:\n",
    "                plt.savefig(f'Evaluation/{question}/individual_@r_{categories[i-1]}.pdf')\n",
    "\n",
    "    elif to_plot == \"all\":\n",
    "        # whole RQ1\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@r', fontsize=15)\n",
    "        plt.ylabel('Metric scores', fontsize=15)\n",
    "        plt.title(f\"{question}: Average metric performances @r\", fontsize=20)\n",
    "        plt.xticks(data_f1.columns+1)\n",
    "        plt.plot(data_f1.columns+1, data_f1.mean(axis=0), color=colors[11], marker='o', label=\"F1\")\n",
    "        plt.plot(data_jacc.columns+1, data_jacc.mean(axis=0), color=colors[12], marker='x', label=\"Jaccard\")\n",
    "        plt.plot(data_rbo.columns+1, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"RBO\")\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/@r_all_metrics.pdf')\n",
    "\n",
    "        # whole RQ1 with stdev\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@r', fontsize=15)\n",
    "        plt.ylabel('Metric scores', fontsize=15)\n",
    "        plt.title(f\"{question}: Average metric performances @r with their standard deviations\", fontsize=20)\n",
    "        plt.xticks(data_f1.columns+1)\n",
    "        plt.plot(data_f1.columns+1, data_f1.mean(axis=0), color=colors[11], marker='o', label=\"F1\")\n",
    "        plt.plot(data_jacc.columns+1, data_jacc.mean(axis=0), color=colors[12], marker='x', label=\"Jaccard\")\n",
    "        plt.plot(data_rbo.columns+1, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"RBO\")\n",
    "        plt.fill_between(data_f1.columns+1, data_f1.mean(axis=0)+data_f1.std(axis=0), data_f1.mean(axis=0)-data_f1.std(axis=0), color=colors[11], alpha=0.1)\n",
    "        plt.fill_between(data_jacc.columns+1, data_jacc.mean(axis=0)+data_jacc.std(axis=0), data_jacc.mean(axis=0)-data_jacc.std(axis=0), color=colors[12], alpha=0.2)\n",
    "        plt.fill_between(data_rbo.columns+1, data_rbo.mean(axis=0)+data_rbo.std(axis=0), data_rbo.mean(axis=0)-data_rbo.std(axis=0), color=colors[9], alpha=0.2)\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/@r_all_metrics_stdev.pdf')\n",
    "\n",
    "        # F1 + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@r', fontsize=15)\n",
    "        plt.ylabel('F1-scores', fontsize=15)\n",
    "        plt.title(f\"{question}: F1-scores @r\", fontsize=20)\n",
    "        plt.xticks(data_f1.columns+1)\n",
    "        plt.plot(data_f1.columns+1, data_f1.mean(axis=0), color=colors[11], marker='o', label=\"avg\")\n",
    "        for i in range(1,len(categories)+1):\n",
    "            plt.plot(data_f1.columns+1, list(data_f1.iloc[(len(cols)*i-len(cols)):len(cols)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=categories[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/@r_F1_categories.pdf')\n",
    "\n",
    "        # Jaccard + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@r', fontsize=15)\n",
    "        plt.ylabel('Jaccard similarity', fontsize=15)\n",
    "        plt.title(f\"{question}: Jaccard similarities @r\", fontsize=20)\n",
    "        plt.xticks(data_jacc.columns+1)\n",
    "        plt.plot(data_jacc.columns+1, data_jacc.mean(axis=0), color=colors[12], marker='x', label=\"avg\")\n",
    "        for i in range(1,len(categories)+1):\n",
    "            plt.plot(data_jacc.columns+1, list(data_jacc.iloc[(len(cols)*i-len(cols)):len(cols)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=categories[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/@r_jacc_categories.pdf')\n",
    "\n",
    "        # rbo + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@r', fontsize=15)\n",
    "        plt.ylabel('RBO', fontsize=15)\n",
    "        plt.title(f\"{question}: RBO @r\", fontsize=20)\n",
    "        plt.xticks(data_rbo.columns+1)\n",
    "        plt.plot(data_rbo.columns+1, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"avg\")\n",
    "        for i in range(1,len(categories)+1):\n",
    "            plt.plot(data_rbo.columns+1, list(data_rbo.iloc[(len(cols)*i-len(cols)):len(cols)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=categories[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/@r_rbo_categories.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_p_metrics(data_rbo, to_plot):\n",
    "    if to_plot == \"category\":\n",
    "        # individual categories with avg metrics\n",
    "        for i in range(1,len(categories)+1):\n",
    "            plt.figure(figsize=(15, 8))\n",
    "            plt.rc('font', size=12)\n",
    "            plt.xlabel('@p', fontsize=15)\n",
    "            plt.ylabel('RBO similarity', fontsize=15)\n",
    "            plt.title(f\"{question}: Average RBO similarity @p for {categories[i-1]}\", fontsize=20)\n",
    "            plt.xticks((data_rbo.columns+1)/10)\n",
    "            plt.plot((data_rbo.columns+1)/10, list(data_rbo.iloc[(len(cols)*i-len(cols)):len(cols)*i].mean(axis=0)), color=colors[9], marker='s', label=\"RBO\")\n",
    "            plt.legend(loc=2)\n",
    "            if save:\n",
    "                plt.savefig(f'Evaluation/{question}/individual_rbo@p_{categories[i-1]}.pdf')\n",
    "\n",
    "    elif to_plot == \"all\":\n",
    "        # whole RQ1\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@p', fontsize=15)\n",
    "        plt.ylabel('RBO similarity', fontsize=15)\n",
    "        plt.title(f\"{question}: Average RBO similarity @p\", fontsize=20)\n",
    "        plt.xticks((data_rbo.columns+1)/10)\n",
    "        plt.plot((data_rbo.columns+1)/10, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"RBO\")\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/rbo@p_all_metrics.pdf')\n",
    "\n",
    "        # whole RQ1 with stdev\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@p', fontsize=15)\n",
    "        plt.ylabel('RBO similarity', fontsize=15)\n",
    "        plt.title(f\"{question}: Average RBO similarity @p with its standard deviation\", fontsize=20)\n",
    "        plt.xticks((data_rbo.columns+1)/10)\n",
    "        plt.plot((data_rbo.columns+1)/10, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"RBO\")\n",
    "        plt.fill_between((data_rbo.columns+1)/10, data_rbo.mean(axis=0)+data_rbo.std(axis=0), data_rbo.mean(axis=0)-data_rbo.std(axis=0), color=colors[9], alpha=0.2)\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/rbo@p_all_metrics_stdev.pdf')\n",
    "\n",
    "        # rbo + categories\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.rc('font', size=12)\n",
    "        plt.xlabel('@p', fontsize=15)\n",
    "        plt.ylabel('RBO', fontsize=15)\n",
    "        plt.title(f\"{question}: RBO similarity @p\", fontsize=20)\n",
    "        plt.xticks((data_rbo.columns+1)/10)\n",
    "        plt.plot((data_rbo.columns+1)/10, data_rbo.mean(axis=0), color=colors[9], marker='s', label=\"avg\")\n",
    "        for i in range(1,len(categories)+1):\n",
    "            plt.plot((data_rbo.columns+1)/10, list(data_rbo.iloc[(len(cols)*i-len(cols)):len(cols)*i].mean(axis=0)), linestyle='--', color=colors[i+2], label=categories[i-1])\n",
    "        plt.legend(loc=2)\n",
    "        if save:\n",
    "            plt.savefig(f'Evaluation/{question}/rbo@p_categories.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clust_perc(clust, step3, perc):\n",
    "    y1 = clust.mean(axis=0)\n",
    "    y2 = step3.mean(axis=0)\n",
    "    y3 = perc.mean(axis=0)\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.rc('font', size=12)\n",
    "    plt.xlabel('Number of reviews', fontsize=15)\n",
    "    plt.ylabel('Percentage', fontsize=15)\n",
    "    plt.title(f\"{question}: Percentage of cluster, successful step3s & reviews with their standard deviations\", fontsize=20)\n",
    "    plt.xticks(range(len(cols)), labels=cols)\n",
    "    plt.plot(cols, y1, color=colors[1], marker='o', label=\"%cluster\")\n",
    "    plt.plot(cols, y2, color=colors[12], marker='h', label=\"%successful step3s\")\n",
    "    plt.plot(cols, y3, color=colors[2], marker='x', label=\"%reviews\")\n",
    "    plt.fill_between(cols, y1+clust.std(axis=0), y1-clust.std(axis=0), color=colors[8], alpha=0.3)\n",
    "    plt.fill_between(cols, y2+step3.std(axis=0), y2-step3.std(axis=0), color=colors[12], alpha=0.2)\n",
    "    plt.fill_between(cols, y3+perc.std(axis=0), y3-perc.std(axis=0), color=colors[3], alpha=0.3)\n",
    "    plt.legend(loc=2)\n",
    "    if save:\n",
    "            plt.savefig(f'Evaluation/{question}/clust_step3_perc_stdev.pdf')\n",
    "        \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.rc('font', size=12)\n",
    "    plt.xlabel('Number of reviews', fontsize=15)\n",
    "    plt.ylabel('Percentage', fontsize=15)\n",
    "    plt.title(f\"{question}: Percentage of cluster, successful step3s & reviews with their standard deviations\", fontsize=20)\n",
    "    plt.xticks(range(len(cols)), labels=cols)\n",
    "    plt.plot(cols, y1, color=colors[1], marker='o', label=\"%cluster\")\n",
    "    plt.plot(cols, y2, color=colors[12], marker='h', label=\"%successful step3s\")\n",
    "    plt.plot(cols, y3, color=colors[2], marker='x', label=\"%reviews\")\n",
    "    plt.legend(loc=2)\n",
    "    if save:\n",
    "            plt.savefig(f'Evaluation/{question}/clust_step3_perc.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "save = False # save figures or not\n",
    "\n",
    "questions = {\"RQ1\": [\"CDs_and_Vinyl\",\"Electronics\",\"Home_and_Kitchen\",\"Movies_and_TV\",\"Video_Games\"]}\n",
    "\n",
    "for question, categories in questions.items():\n",
    "\n",
    "    cols = ['10', '20', '50', '100', '±250', '430-500', '>1000']\n",
    "\n",
    "    clust_RQ = pd.DataFrame(columns=cols)\n",
    "    run_RQ = pd.DataFrame(columns=cols)\n",
    "    len_ranking_RQ = pd.DataFrame(columns=cols)\n",
    "    perc_ranking_RQ = pd.DataFrame(columns=cols)\n",
    "    perc_step3_RQ = pd.DataFrame(columns=cols)\n",
    "    f1_r_RQ = [] \n",
    "    f1_nr_rev_RQ = pd.DataFrame(columns=cols)\n",
    "    jacc_r_RQ = []\n",
    "    jacc_nr_rev_RQ = pd.DataFrame(columns=cols)\n",
    "    rbo_r_RQ = []\n",
    "    rbo_p_RQ = []\n",
    "    rbo_nr_rev_RQ = pd.DataFrame(columns=cols)\n",
    "\n",
    "    for category in categories:\n",
    "        with open(f'Evaluation/{question}/evaluations.txt', 'a') as f:\n",
    "            clust_cat = []\n",
    "            run_cat = []\n",
    "            len_ranking_cat = []\n",
    "            perc_ranking_cat = []\n",
    "            perc_step3_cat = []\n",
    "            f1_nr_rev_cat = []\n",
    "            jacc_nr_rev_cat = []\n",
    "            rbo_nr_rev_cat = []\n",
    "\n",
    "            nr_revs = [10, 20, 50, 100]\n",
    "            if category == \"CDs_and_Vinyl\":\n",
    "                nr_revs.extend([253, 499, 1045])\n",
    "            elif category == \"Electronics\":\n",
    "                nr_revs.extend([250, 481, 1475])\n",
    "            elif category == \"Home_and_Kitchen\":\n",
    "                nr_revs.extend([257, 459, 4130])\n",
    "            elif category == \"Movies_and_TV\":\n",
    "                nr_revs.extend([247, 499, 1491])\n",
    "            elif category == \"Video_Games\":\n",
    "                nr_revs.extend([251, 431, 2593])\n",
    "\n",
    "            for nr_rev in nr_revs:\n",
    "                f1_r_cat = []\n",
    "                jacc_r_cat = []\n",
    "                rbo_r_cat = []\n",
    "                rbo_p_cat = []\n",
    "                \n",
    "                path = f'Results/{question}/{category}/{nr_rev}'\n",
    "\n",
    "                start_evaluation()\n",
    "\n",
    "                print(f'\\nClustered:\\n{clust_cat}', file=f)\n",
    "                print(f'\\nRun time:\\n{run_cat}\\n\\n', file=f)\n",
    "                print(f'\\nLength of final ranking:\\n{len_ranking_cat}\\n', file=f)\n",
    "                print(f'\\nPercentage of final ranking:\\n{perc_ranking_cat}\\n', file=f)\n",
    "                print(f'\\nPercentage of successful step3s:\\n{perc_step3_cat}\\n', file=f)\n",
    "                print(f'\\nF1-scores:\\n{f1_nr_rev_cat}\\n', file=f)\n",
    "                print(f'\\nJaccard distances:\\n{jacc_nr_rev_cat}\\n', file=f)\n",
    "                print(f'\\nRBO distances:\\n{rbo_nr_rev_cat}\\n', file=f)\n",
    "\n",
    "                f1_r_RQ.append(f1_r_cat)\n",
    "                jacc_r_RQ.append(jacc_r_cat)\n",
    "                rbo_r_RQ.append(rbo_r_cat)\n",
    "                rbo_p_RQ.append(rbo_p_cat)\n",
    "            \n",
    "        clust_RQ.loc[len(clust_RQ)] = clust_cat\n",
    "        run_RQ.loc[len(run_RQ)] = run_cat\n",
    "        len_ranking_RQ.loc[len(len_ranking_RQ)] = len_ranking_cat\n",
    "        perc_ranking_RQ.loc[len(perc_ranking_RQ)] = perc_ranking_cat\n",
    "        perc_step3_RQ.loc[len(perc_step3_RQ)] = perc_step3_cat\n",
    "        f1_nr_rev_RQ.loc[len(f1_nr_rev_RQ)] = f1_nr_rev_cat\n",
    "        jacc_nr_rev_RQ.loc[len(jacc_nr_rev_RQ)] = jacc_nr_rev_cat\n",
    "        rbo_nr_rev_RQ.loc[len(rbo_nr_rev_RQ)] = rbo_nr_rev_cat\n",
    "            \n",
    "\n",
    "        plot_clust_run(pd.DataFrame([clust_cat]), pd.DataFrame([run_cat]), \"category\")\n",
    "        plot_metrics(pd.DataFrame([f1_nr_rev_cat]), pd.DataFrame([jacc_nr_rev_cat]), pd.DataFrame([rbo_nr_rev_cat]), \"category\")\n",
    "\n",
    "    plot_clust_run(clust_RQ, run_RQ, \"all\")\n",
    "    plot_ranking(len_ranking_RQ, perc_ranking_RQ, perc_step3_RQ)\n",
    "    plot_metrics(f1_nr_rev_RQ, jacc_nr_rev_RQ, rbo_nr_rev_RQ, \"all\")\n",
    "    plot_r_metrics(pd.DataFrame(f1_r_RQ), pd.DataFrame(jacc_r_RQ), pd.DataFrame(rbo_r_RQ), \"category\")\n",
    "    plot_r_metrics(pd.DataFrame(f1_r_RQ), pd.DataFrame(jacc_r_RQ), pd.DataFrame(rbo_r_RQ), \"all\")\n",
    "    plot_p_metrics(pd.DataFrame(rbo_p_RQ), \"category\")\n",
    "    plot_p_metrics(pd.DataFrame(rbo_p_RQ), \"all\")\n",
    "    plot_clust_perc(clust_RQ, perc_step3_RQ, perc_ranking_RQ)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
